{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Minor Project 3.ipynb",
      "provenance": [],
      "collapsed_sections": [
        "gr5ehALHjj4h",
        "_H-7gPuEOGkC",
        "nKZkfJN3ONxV",
        "UlBHjVyJOYTQ",
        "38bKrd62qt3N",
        "hU5SXpVbNL05",
        "aeUsV-UAdl0x",
        "4gcrGxYKkRUI",
        "IxpbmgDG-qaW",
        "A2F6bwQsaQ49",
        "L73Vx1kT-z0P",
        "h_oFFTA6AECx",
        "xXou-V-wfsbW",
        "eK9rsoSNAPqG",
        "f2Z87ndxKVhc",
        "bKP1fbJfJvhH"
      ],
      "machine_shape": "hm"
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gr5ehALHjj4h"
      },
      "source": [
        "# Importing"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "msmxXEW1vCNE",
        "outputId": "f5bfa5b5-0c28-47f6-8513-7ca1798777cf"
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "execution_count": 108,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GUgc1a0A4OBP"
      },
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "import cv2 \n",
        "import os\n",
        "import glob\n",
        "\n",
        "import random\n",
        "from skimage import transform\n",
        "import skimage\n",
        "\n",
        "import sklearn\n",
        "from sklearn.model_selection import train_test_split \n",
        "\n",
        "import keras\n",
        "from keras.callbacks import ModelCheckpoint\n",
        "\n",
        "from keras.preprocessing.image import ImageDataGenerator,array_to_img,img_to_array,load_img\n",
        "\n",
        "from keras.layers import LSTM\n",
        "from keras.models import Model \n",
        "from keras.layers import Input,Dense,TimeDistributed\n",
        "\n",
        "from keras.layers import Dropout\n"
      ],
      "execution_count": 17,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_H-7gPuEOGkC"
      },
      "source": [
        "# Making Frames"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nKZkfJN3ONxV"
      },
      "source": [
        "## Positive Cases"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "B2Te1jLPzX7k"
      },
      "source": [
        "os.chdir('/content/drive/MyDrive/Minor Project 3/CADP/Videos/Positive')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dp0eipbyGQpb"
      },
      "source": [
        "def FrameCapture(path,folder): \n",
        "  cap = cv2.VideoCapture(path)\n",
        "  property_id = int(cv2.CAP_PROP_FRAME_COUNT) \n",
        "  length = int(cv2.VideoCapture.get(cap, property_id))\n",
        "  count = 0\n",
        "  success = 1\n",
        "  \n",
        "  if length > 100:\n",
        "    cut = length-99\n",
        "  else:\n",
        "    cut = 0\n",
        "\n",
        "  #dir = os.path.join(os.getcwd(),folder)\n",
        "  dir =  \"/content/drive/MyDrive/Minor Project 3/CADP/Frames/Positive/\"+folder\n",
        "  os.mkdir(dir)\n",
        " \n",
        "  #print(folder,cut,sep=' ')\n",
        "  #while success:\n",
        "  for i in range(length):\n",
        "    success, image = cap.read()\n",
        "    if count >= cut :\n",
        "      n = count-cut\n",
        "      #cv2.imwrite(dir+\"/frame%d.jpg\" % n, image) \n",
        "      cv2.imwrite(dir+'/'+str(n)+'.jpg', image)\n",
        "    count += 1\n",
        "\n",
        "\n",
        "#temp_dir = \"/drive/MyDrive/Minor Project 3/CADP/Train/Positive\"\n",
        "temp_dir = os.getcwd()\n",
        "\n",
        "for video_file in os.listdir(temp_dir):\n",
        "  path = temp_dir+\"/\"+video_file\n",
        "  FrameCapture(path,video_file)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BBJW-HewOUP_"
      },
      "source": [
        "## Negative Cases"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Qdo-d8LvcMm-"
      },
      "source": [
        "os.chdir('/content/drive/MyDrive/Minor Project 3/CADP/Videos/Negative')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tsRRn37HOXvt"
      },
      "source": [
        "def FrameCapture(path,folder): \n",
        "  cap = cv2.VideoCapture(path)\n",
        "  property_id = int(cv2.CAP_PROP_FRAME_COUNT) \n",
        "  length = int(cv2.VideoCapture.get(cap, property_id))\n",
        "  count = 0\n",
        "  success = 1\n",
        "  \n",
        "  if length > 100:\n",
        "    cut = length-99\n",
        "  else:\n",
        "    cut = 0\n",
        "\n",
        "  #dir = os.path.join(os.getcwd(),folder)\n",
        "  dir =  \"/content/drive/MyDrive/Minor Project 3/CADP/Frames/Negative/\"+folder\n",
        "  os.mkdir(dir)\n",
        " \n",
        "  #print(folder,cut,sep=' ')\n",
        "  #while success:\n",
        "  for i in range(length):\n",
        "    success, image = cap.read()\n",
        "    if count >= cut :\n",
        "      n = count-cut\n",
        "      #cv2.imwrite(dir+\"/frame%d.jpg\" % n, image) \n",
        "      cv2.imwrite(dir+'/'+str(n)+'.jpg', image)\n",
        "    count += 1\n",
        "\n",
        "\n",
        "temp_dir = os.getcwd()\n",
        "\n",
        "for video_file in os.listdir(temp_dir):\n",
        "  path = temp_dir+\"/\"+video_file\n",
        "  FrameCapture(path,video_file)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UlBHjVyJOYTQ"
      },
      "source": [
        "# More Preprocessing"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Y4NBFe0_jNye"
      },
      "source": [
        "## Storing Positive and Negative Frames in diff variables"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0KC183uDg_D-",
        "outputId": "1cea1730-7cb6-4ff5-c719-3f80532ad604"
      },
      "source": [
        "os.chdir('/content/drive/MyDrive/Minor Project 3/CADP/Frames')\n",
        "\n",
        "img_filepath = os.getcwd()                                      \n",
        "neg = glob.glob(img_filepath + '/Negative/*.mp4')           \n",
        "pos = glob.glob(img_filepath + '/Positive/*.mp4')             \n",
        "\n",
        "all_files = np.concatenate((pos, neg))\n",
        "print(len(neg), len(pos))                   "
      ],
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "140 116\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "YJUUoSvtp-Zp",
        "outputId": "779f189d-3aa8-41de-9c16-99c0168e8ed8"
      },
      "source": [
        "len(all_files)"
      ],
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "256"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 19
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xH20hlmQjVy9"
      },
      "source": [
        "## Labelling Data"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ADkw1Pm7sRK4",
        "outputId": "4b61f8b7-ba8f-44c2-caf0-d58ddbbbff7f"
      },
      "source": [
        "#Labelling positive cases\n",
        "\n",
        "pos_label = [[0, 1]]*len(pos)\n",
        "len(pos_label)"
      ],
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "116"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 20
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4azc78SAtsQh",
        "outputId": "6e0e47d4-5c73-4c31-d1f0-5d60f5e198c5"
      },
      "source": [
        "#Labelling negative cases\n",
        "\n",
        "neg_label = [[1, 0]]*len(neg)\n",
        "len(neg_label)"
      ],
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "140"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 21
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "OlWZ1H-IqQHr",
        "outputId": "0c1d9178-1df8-442d-9b8a-15ea6a349f8f"
      },
      "source": [
        "# Storing both in a variable\n",
        "\n",
        "labels = pos_label + neg_label\n",
        "len(labels)"
      ],
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "256"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 22
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "38bKrd62qt3N"
      },
      "source": [
        "# Useless Functions"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "M_ZPDnEdenRQ"
      },
      "source": [
        "## Function to Resize and convert Frames to Grayscale"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cW6d1Ego5kzi"
      },
      "source": [
        "def load_set(videofile):\n",
        "    #vidcap = cv2.VideoCapture(videofile)\n",
        "    error = ''    \n",
        "    success = True\n",
        "    flag = 0\n",
        "    #while success:\n",
        "        #success, img = vidcap.read()  \n",
        "\n",
        "    frames = [] \n",
        "    for j in range(99):\n",
        "        flag = 0\n",
        "        try:\n",
        "          img = cv2.imread(videofile + '/'+str(j) + '.jpg')\n",
        "          #success, img = vidcap.read()\n",
        "          flag += 1\n",
        "\n",
        "          #print(np.array(img).shape)\n",
        "\n",
        "          tmp = skimage.color.rgb2gray(np.array(img))\n",
        "          flag += 1\n",
        "          tmp = transform.resize(tmp, (144, 256))\n",
        "          flag += 1\n",
        "          \n",
        "          frames.append(tmp)     \n",
        "        except:\n",
        "          print(flag, end = ' ')\n",
        "          pass \n",
        "\n",
        "        #if np.shape(frames[0])!=(144,256):\n",
        "            #error = 'Video is not the correct resolution.'\n",
        "    #vidcap.release()\n",
        "    return frames, error"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zKFOooV1NaxP"
      },
      "source": [
        "from PIL import Image\n",
        "\n",
        "videofile = '/content/drive/MyDrive/Minor Project 3/CADP/Frames/Positive/55.mp4'\n",
        "\n",
        "main_path = videofile\n",
        "\n",
        "list_images_path = list(sorted(os.listdir(main_path)))\n",
        "\n",
        "temp = []\n",
        "list_images_path\n",
        "\n",
        "for path in list_images_path:\n",
        "  img1 = cv2.imread(os.path.join(main_path, path))\n",
        "  img1.shape\n",
        "  img1.resize(144,256)\n",
        "  #img1 = cv2.cvtColor(img1, cv2.COLOR_BGR2GRAY)\n",
        "  temp.append(img1)\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fp4Qpk6bQMBt",
        "outputId": "5b3185f1-71a4-4fb6-c4ad-bfe1e960b1be"
      },
      "source": [
        "temp[0].shape"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(144, 256)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 15
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "IWB9s_doP7nx",
        "outputId": "adb47a67-b32b-4723-91a8-e394a5714b59"
      },
      "source": [
        "len(temp)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "99"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 16
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XxhEnjHkNapW"
      },
      "source": [
        "def load_set(videofile):\n",
        "    #vidcap = cv2.VideoCapture(videofile)\n",
        "    error = ''    \n",
        "    success = True\n",
        "    flag = 0\n",
        "    #while success:\n",
        "        #success, img = vidcap.read()  \n",
        "\n",
        "    frames = [] \n",
        "    for j in range(99):\n",
        "        flag = 0\n",
        "        try:\n",
        "          img = cv2.imread(videofile + '/'+str(j) + '.jpg')\n",
        "          #success, img = vidcap.read()\n",
        "          flag += 1\n",
        "\n",
        "          #print(np.array(img).shape)\n",
        "\n",
        "          tmp = skimage.color.rgb2gray(np.array(img))\n",
        "          flag += 1\n",
        "          tmp = transform.resize(tmp, (144, 256))\n",
        "          flag += 1\n",
        "          \n",
        "          frames.append(tmp)     \n",
        "        except:\n",
        "          print(flag, end = ' ')\n",
        "          pass \n",
        "\n",
        "        #if np.shape(frames[0])!=(144,256):\n",
        "            #error = 'Video is not the correct resolution.'\n",
        "    #vidcap.release()\n",
        "    return frames, error"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zyQOPLpZe1da"
      },
      "source": [
        "## Function to load horizontally flipped frames "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dxakBhkk50Vb"
      },
      "source": [
        "def hori_flipped_load_set(videofile):\n",
        "  \n",
        "  vidcap = cv2.VideoCapture(videofile)\n",
        "  error = ''\n",
        "  success = True\n",
        "  \n",
        "  while success:\n",
        "    success, img = vidcap.read() \n",
        "    frames = []  \n",
        "    for j in range(99):\n",
        "        try:\n",
        "          success, img = vidcap.read()\n",
        "\n",
        "          tmp = skimage.color.rgb2gray(np.array(img))\n",
        "          tmp = skimage.transform.resize(tmp, (144, 256))\n",
        "          tmp = np.array(tmp)\n",
        "          tmp = np.flip(tmp, axis = 1)\n",
        "\n",
        "          frames.append(tmp)\n",
        "\n",
        "        except:\n",
        "          pass\n",
        "    if np.shape(frames[0])!=(144,256):\n",
        "      error = 'Video is not the correct resolution.'\n",
        "  vidcap.release()\n",
        "  return frames, error\t"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "oV2GylL4jY5l"
      },
      "source": [
        "## Make dataset function"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "s-wtTQYvjZO_"
      },
      "source": [
        "def make_dataset(rand):\n",
        "  seq1 = np.zeros( (2*len(rand), 99, 144, 256)) \n",
        "  for i,fi in enumerate(rand):                   \n",
        "    print((i, fi))                           \n",
        "    if fi[-4:] == '.mp4' and i%2==0:\t\t\n",
        "      t = load_set(fi)             \n",
        "\n",
        "    elif fi[-4:] == '.mp4' and i%2==1:\n",
        "      t = hori_flipped_load_set(fi)    \n",
        "       \n",
        "    #if t.shape==(99,144,256):\n",
        "    if(len(t) == 99 and len(t[0]) == 144 and len(t[0][0]) == 256):                 \n",
        "      seq1[i] = t                            \n",
        "    else:# TypeError:\n",
        "      print(\"Error\")\n",
        "      pass                              \n",
        "  print((seq1.shape))\n",
        "  return seq1"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "id": "LJj6RDb5LWY_",
        "outputId": "a5f4d5f4-8c82-42af-db2f-aeb5bb9e6e50"
      },
      "source": [
        "os.getcwd()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "'/content/drive/My Drive/Minor Project 3/CADP/Frames'"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 23
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hU5SXpVbNL05"
      },
      "source": [
        "# Actual Functions"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OcyFczgQQMNc"
      },
      "source": [
        "def load_set(img_path):\n",
        "  img = load_img(img_path)\n",
        "  tmp = skimage.color.rgb2gray(np.array(img))\n",
        "  tmp = transform.resize(tmp, (144, 256))\n",
        "  return tmp\n",
        "\n",
        "def horizontal_flip(img_path):\n",
        "  img = load_img(img_path)\n",
        "  tmp = skimage.color.rgb2gray(np.array(img))\n",
        "  tmp = skimage.transform.resize(tmp, (144, 256))\n",
        "  tmp = np.array(tmp)\n",
        "  tmp = np.flip(tmp, axis = 1)\n",
        "  return tmp\n"
      ],
      "execution_count": 61,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "US3aeBRWQMHl"
      },
      "source": [
        "def call_load_data(path):\n",
        "  count = 0\n",
        "  x = []\n",
        "\n",
        "  for files in os.listdir(path):\n",
        "    frames = []\n",
        "\n",
        "    img_path = str(path) + \"/\"+str(files.decode(\"utf-8\"))\n",
        "\n",
        "    if count < 99:\n",
        "      count = count + 1\n",
        "      img = load_set(img_path)\n",
        "    x.append(img)\n",
        "\n",
        "  return x\n",
        "\n",
        "def call_horizontal_flip(path):\n",
        "  count = 0\n",
        "  x = []\n",
        "  for files in os.listdir(path):\n",
        "    frames = []\n",
        "    img_path = str(path) + \"/\"+str(files.decode(\"utf-8\"))\n",
        "    if count < 99:\n",
        "      count = count + 1\n",
        "      img = horizontal_flip(img_path)\n",
        "    x.append(img)\n",
        "\n",
        "  return x"
      ],
      "execution_count": 62,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bP0CVi-BQMBX"
      },
      "source": [
        "def make_dataset(rand):\n",
        "  seq1 = np.zeros( (len(rand), 99, 144, 256)) \n",
        "  #seq1 = np.zeros( (2*len(rand), 99, 144, 256)) \n",
        " \n",
        "  #print(type(rand))\n",
        "  for i, fi in enumerate(rand):                   \n",
        "    print((i, fi))                           \n",
        "    if fi[-4:] == '.mp4' and i%2==0:\t\t\n",
        "      t = call_load_data(fi)             \n",
        "\n",
        "    elif fi[-4:] == '.mp4' and i%2==1:\n",
        "      t = call_horizontal_flip(fi)   \n",
        "       \n",
        "    if(len(t) == 99 and len(t[0]) == 144 and len(t[0][0]) == 256):                 \n",
        "      seq1[i] = t   \n",
        "                       \n",
        "    else:\n",
        "      print(\"Error\")\n",
        "      print('Dimensions are - ', len(t), len(t[0]), len(t[0][0]), sep = \" \")\n",
        "      pass  \n",
        "                      \n",
        "  print((seq1.shape))\n",
        "  return seq1"
      ],
      "execution_count": 63,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "aeUsV-UAdl0x"
      },
      "source": [
        "# Even More Preprocessing"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4gcrGxYKkRUI"
      },
      "source": [
        "## Test Train Split"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4G1_Cu4JlOFn",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "outputId": "3e7824ef-9dc9-4be7-e080-b018c2f14c88"
      },
      "source": [
        "##### split data into training and validation (sets and shuffle)\n",
        "x_train, x_test, y_train, y_test = train_test_split(all_files, labels, test_size=0.40, random_state=0)  \n",
        "x_train = np.asarray(x_train); y_train = np.asarray(y_train);                         \n"
      ],
      "execution_count": 44,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "''"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 44
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9AK8tgkSvKoY",
        "outputId": "61271ce8-662c-4434-adcd-f31d77609dd5"
      },
      "source": [
        "print(len(x_train))\n",
        "print(len(y_train))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "153\n",
            "153\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-B5GBH9caC4C",
        "outputId": "7ebed9ec-0705-4f85-8bf2-bfd458d0a447"
      },
      "source": [
        "print(len(x_test))\n",
        "print(len(y_test))"
      ],
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "103\n",
            "103\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "b4ojtR6GXNjX"
      },
      "source": [
        "#Req libraries\n",
        "import numpy as np\n",
        "#import pandas as pd\n",
        "#import matplotlib.pyplot as plt\n",
        "\n",
        "#import cv2 \n",
        "import os\n",
        "#import glob\n",
        "\n",
        "#import random\n",
        "#from skimage import transform\n",
        "#import skimage\n",
        "\n",
        "#import sklearn\n",
        "#from sklearn.model_selection import train_test_split \n",
        "\n",
        "#import keras\n",
        "from keras.callbacks import ModelCheckpoint\n",
        "\n",
        "#from keras.preprocessing.image import ImageDataGenerator,array_to_img,img_to_array,load_img\n",
        "\n",
        "from keras.layers import LSTM\n",
        "from keras.models import Model \n",
        "from keras.layers import Input,Dense,TimeDistributed\n",
        "\n",
        "from keras.layers import Dropout\n"
      ],
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_xCH_qlkLk6_"
      },
      "source": [
        "frame , row, col =(99,144,256)\n",
        "row_hidden = 128\n",
        "col_hidden = 128\n",
        "batch_size = 64       #224\n",
        "num_classes = 2\n",
        "epochs = 20"
      ],
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0EUwFwAuNJlg"
      },
      "source": [
        "x =Input(shape=(frame, row, col))\n",
        "encoded_rows = TimeDistributed(LSTM(row_hidden))(x) \n",
        "encoded_columns =LSTM(col_hidden)(encoded_rows)"
      ],
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5vy8wiKAP2Bv"
      },
      "source": [
        "'''\n",
        "inputs = tf.keras.Input(shape=(3,))\n",
        "x = tf.keras.layers.Dense(4, activation=tf.nn.relu)(inputs)\n",
        "outputs = tf.keras.layers.Dense(5, activation=tf.nn.softmax)(x)\n",
        "model = tf.keras.Model(inputs=inputs, outputs=outputs)\n",
        "'''\n",
        "layer2 = Dense(128, activation='relu')(encoded_columns)\n",
        "layer3 = Dropout(.2)(layer2)\n",
        "layer4 = Dense(64, activation='relu')(layer3)\n",
        "layer5 = Dropout(.2)(layer4)\n",
        "prediction = Dense(num_classes, activation='softmax')(layer5)\n",
        "\n",
        "model = Model(x, prediction)"
      ],
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "kcYwS1x8kZ65",
        "outputId": "8a0e84d6-6486-4f1b-cc13-ebbbee2a0b6a"
      },
      "source": [
        "model.compile(loss='categorical_crossentropy', optimizer='NAdam', metrics=['accuracy']) \n",
        "model.summary()"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"model\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "input_1 (InputLayer)         [(None, 99, 144, 256)]    0         \n",
            "_________________________________________________________________\n",
            "time_distributed (TimeDistri (None, 99, 128)           197120    \n",
            "_________________________________________________________________\n",
            "lstm_1 (LSTM)                (None, 128)               131584    \n",
            "_________________________________________________________________\n",
            "dense (Dense)                (None, 128)               16512     \n",
            "_________________________________________________________________\n",
            "dropout (Dropout)            (None, 128)               0         \n",
            "_________________________________________________________________\n",
            "dense_1 (Dense)              (None, 64)                8256      \n",
            "_________________________________________________________________\n",
            "dropout_1 (Dropout)          (None, 64)                0         \n",
            "_________________________________________________________________\n",
            "dense_2 (Dense)              (None, 2)                 130       \n",
            "=================================================================\n",
            "Total params: 353,602\n",
            "Trainable params: 353,602\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "IxpbmgDG-qaW"
      },
      "source": [
        "## Creating testing and validation numpy arrays"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8pN5u8ypz_me",
        "outputId": "957561bd-9548-400d-94b6-427fe39e6483"
      },
      "source": [
        "x_testA = make_dataset(x_testA[0:batch_size])"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(0, '/content/drive/MyDrive/Minor Project 3/CADP/Frames/Negative/2.mp4')\n",
            "(1, '/content/drive/MyDrive/Minor Project 3/CADP/Frames/Negative/56.mp4')\n",
            "(2, '/content/drive/MyDrive/Minor Project 3/CADP/Frames/Positive/77.mp4')\n",
            "(3, '/content/drive/MyDrive/Minor Project 3/CADP/Frames/Positive/60.mp4')\n",
            "(4, '/content/drive/MyDrive/Minor Project 3/CADP/Frames/Negative/89.mp4')\n",
            "(5, '/content/drive/MyDrive/Minor Project 3/CADP/Frames/Negative/110.mp4')\n",
            "(6, '/content/drive/MyDrive/Minor Project 3/CADP/Frames/Positive/19.mp4')\n",
            "(7, '/content/drive/MyDrive/Minor Project 3/CADP/Frames/Negative/108.mp4')\n",
            "(8, '/content/drive/MyDrive/Minor Project 3/CADP/Frames/Positive/16.mp4')\n",
            "(9, '/content/drive/MyDrive/Minor Project 3/CADP/Frames/Negative/48.mp4')\n",
            "(10, '/content/drive/MyDrive/Minor Project 3/CADP/Frames/Positive/75.mp4')\n",
            "(11, '/content/drive/MyDrive/Minor Project 3/CADP/Frames/Positive/8.mp4')\n",
            "(12, '/content/drive/MyDrive/Minor Project 3/CADP/Frames/Positive/94.mp4')\n",
            "(13, '/content/drive/MyDrive/Minor Project 3/CADP/Frames/Negative/63.mp4')\n",
            "(14, '/content/drive/MyDrive/Minor Project 3/CADP/Frames/Negative/122.mp4')\n",
            "(15, '/content/drive/MyDrive/Minor Project 3/CADP/Frames/Positive/34.mp4')\n",
            "(16, '/content/drive/MyDrive/Minor Project 3/CADP/Frames/Positive/116.mp4')\n",
            "(17, '/content/drive/MyDrive/Minor Project 3/CADP/Frames/Negative/54.mp4')\n",
            "(18, '/content/drive/MyDrive/Minor Project 3/CADP/Frames/Negative/107.mp4')\n",
            "(19, '/content/drive/MyDrive/Minor Project 3/CADP/Frames/Negative/140.mp4')\n",
            "(20, '/content/drive/MyDrive/Minor Project 3/CADP/Frames/Negative/115.mp4')\n",
            "(21, '/content/drive/MyDrive/Minor Project 3/CADP/Frames/Positive/109.mp4')\n",
            "(22, '/content/drive/MyDrive/Minor Project 3/CADP/Frames/Positive/17.mp4')\n",
            "(23, '/content/drive/MyDrive/Minor Project 3/CADP/Frames/Positive/95.mp4')\n",
            "(24, '/content/drive/MyDrive/Minor Project 3/CADP/Frames/Positive/76.mp4')\n",
            "(25, '/content/drive/MyDrive/Minor Project 3/CADP/Frames/Positive/90.mp4')\n",
            "(26, '/content/drive/MyDrive/Minor Project 3/CADP/Frames/Negative/18.mp4')\n",
            "(27, '/content/drive/MyDrive/Minor Project 3/CADP/Frames/Positive/1.mp4')\n",
            "(28, '/content/drive/MyDrive/Minor Project 3/CADP/Frames/Negative/126.mp4')\n",
            "(29, '/content/drive/MyDrive/Minor Project 3/CADP/Frames/Positive/62.mp4')\n",
            "(30, '/content/drive/MyDrive/Minor Project 3/CADP/Frames/Negative/7.mp4')\n",
            "(31, '/content/drive/MyDrive/Minor Project 3/CADP/Frames/Positive/53.mp4')\n",
            "(32, '/content/drive/MyDrive/Minor Project 3/CADP/Frames/Positive/67.mp4')\n",
            "(33, '/content/drive/MyDrive/Minor Project 3/CADP/Frames/Positive/27.mp4')\n",
            "(34, '/content/drive/MyDrive/Minor Project 3/CADP/Frames/Negative/103.mp4')\n",
            "(35, '/content/drive/MyDrive/Minor Project 3/CADP/Frames/Negative/52.mp4')\n",
            "(36, '/content/drive/MyDrive/Minor Project 3/CADP/Frames/Negative/113.mp4')\n",
            "(37, '/content/drive/MyDrive/Minor Project 3/CADP/Frames/Positive/41.mp4')\n",
            "(38, '/content/drive/MyDrive/Minor Project 3/CADP/Frames/Positive/14.mp4')\n",
            "(39, '/content/drive/MyDrive/Minor Project 3/CADP/Frames/Positive/5.mp4')\n",
            "(40, '/content/drive/MyDrive/Minor Project 3/CADP/Frames/Positive/96.mp4')\n",
            "(41, '/content/drive/MyDrive/Minor Project 3/CADP/Frames/Positive/25.mp4')\n",
            "(42, '/content/drive/MyDrive/Minor Project 3/CADP/Frames/Positive/31.mp4')\n",
            "(43, '/content/drive/MyDrive/Minor Project 3/CADP/Frames/Negative/111.mp4')\n",
            "(44, '/content/drive/MyDrive/Minor Project 3/CADP/Frames/Positive/61.mp4')\n",
            "(45, '/content/drive/MyDrive/Minor Project 3/CADP/Frames/Positive/57.mp4')\n",
            "(46, '/content/drive/MyDrive/Minor Project 3/CADP/Frames/Negative/38.mp4')\n",
            "(47, '/content/drive/MyDrive/Minor Project 3/CADP/Frames/Negative/6.mp4')\n",
            "(48, '/content/drive/MyDrive/Minor Project 3/CADP/Frames/Positive/20.mp4')\n",
            "(49, '/content/drive/MyDrive/Minor Project 3/CADP/Frames/Negative/69.mp4')\n",
            "(50, '/content/drive/MyDrive/Minor Project 3/CADP/Frames/Negative/32.mp4')\n",
            "(51, '/content/drive/MyDrive/Minor Project 3/CADP/Frames/Positive/55.mp4')\n",
            "(52, 99, 144, 256)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MAS9aM4jrhfv"
      },
      "source": [
        "#Saving Numpy Array x_testA\n",
        "os.chdir(\"/content/drive/MyDrive/Minor Project 3/\")\n",
        "\n",
        "np.save('x_testA.npy',x_testA)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_isxxYxINLP7",
        "outputId": "792a72d2-80f5-45cf-c949-f57ae3ac9f23"
      },
      "source": [
        "x_testB = make_dataset(x_testB[0:batch_size])"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(0, '/content/drive/MyDrive/Minor Project 3/CADP/Frames/Negative/55.mp4')\n",
            "(1, '/content/drive/MyDrive/Minor Project 3/CADP/Frames/Positive/114.mp4')\n",
            "(2, '/content/drive/MyDrive/Minor Project 3/CADP/Frames/Negative/12.mp4')\n",
            "(3, '/content/drive/MyDrive/Minor Project 3/CADP/Frames/Positive/84.mp4')\n",
            "(4, '/content/drive/MyDrive/Minor Project 3/CADP/Frames/Negative/50.mp4')\n",
            "(5, '/content/drive/MyDrive/Minor Project 3/CADP/Frames/Negative/79.mp4')\n",
            "(6, '/content/drive/MyDrive/Minor Project 3/CADP/Frames/Negative/117.mp4')\n",
            "(7, '/content/drive/MyDrive/Minor Project 3/CADP/Frames/Negative/100.mp4')\n",
            "(8, '/content/drive/MyDrive/Minor Project 3/CADP/Frames/Positive/64.mp4')\n",
            "(9, '/content/drive/MyDrive/Minor Project 3/CADP/Frames/Negative/33.mp4')\n",
            "(10, '/content/drive/MyDrive/Minor Project 3/CADP/Frames/Negative/46.mp4')\n",
            "(11, '/content/drive/MyDrive/Minor Project 3/CADP/Frames/Negative/101.mp4')\n",
            "(12, '/content/drive/MyDrive/Minor Project 3/CADP/Frames/Positive/91.mp4')\n",
            "(13, '/content/drive/MyDrive/Minor Project 3/CADP/Frames/Negative/68.mp4')\n",
            "(14, '/content/drive/MyDrive/Minor Project 3/CADP/Frames/Negative/47.mp4')\n",
            "(15, '/content/drive/MyDrive/Minor Project 3/CADP/Frames/Positive/74.mp4')\n",
            "(16, '/content/drive/MyDrive/Minor Project 3/CADP/Frames/Negative/99.mp4')\n",
            "(17, '/content/drive/MyDrive/Minor Project 3/CADP/Frames/Negative/13.mp4')\n",
            "(18, '/content/drive/MyDrive/Minor Project 3/CADP/Frames/Negative/53.mp4')\n",
            "(19, '/content/drive/MyDrive/Minor Project 3/CADP/Frames/Positive/103.mp4')\n",
            "(20, '/content/drive/MyDrive/Minor Project 3/CADP/Frames/Negative/67.mp4')\n",
            "(21, '/content/drive/MyDrive/Minor Project 3/CADP/Frames/Positive/46.mp4')\n",
            "(22, '/content/drive/MyDrive/Minor Project 3/CADP/Frames/Negative/131.mp4')\n",
            "(23, '/content/drive/MyDrive/Minor Project 3/CADP/Frames/Negative/34.mp4')\n",
            "(24, '/content/drive/MyDrive/Minor Project 3/CADP/Frames/Positive/89.mp4')\n",
            "(25, '/content/drive/MyDrive/Minor Project 3/CADP/Frames/Negative/130.mp4')\n",
            "(26, '/content/drive/MyDrive/Minor Project 3/CADP/Frames/Positive/9.mp4')\n",
            "(27, '/content/drive/MyDrive/Minor Project 3/CADP/Frames/Positive/56.mp4')\n",
            "(28, '/content/drive/MyDrive/Minor Project 3/CADP/Frames/Negative/83.mp4')\n",
            "(29, '/content/drive/MyDrive/Minor Project 3/CADP/Frames/Positive/38.mp4')\n",
            "(30, '/content/drive/MyDrive/Minor Project 3/CADP/Frames/Negative/75.mp4')\n",
            "(31, '/content/drive/MyDrive/Minor Project 3/CADP/Frames/Negative/25.mp4')\n",
            "(32, '/content/drive/MyDrive/Minor Project 3/CADP/Frames/Positive/110.mp4')\n",
            "(33, '/content/drive/MyDrive/Minor Project 3/CADP/Frames/Negative/77.mp4')\n",
            "(34, '/content/drive/MyDrive/Minor Project 3/CADP/Frames/Negative/11.mp4')\n",
            "(35, '/content/drive/MyDrive/Minor Project 3/CADP/Frames/Negative/42.mp4')\n",
            "(36, '/content/drive/MyDrive/Minor Project 3/CADP/Frames/Negative/66.mp4')\n",
            "(37, '/content/drive/MyDrive/Minor Project 3/CADP/Frames/Positive/6.mp4')\n",
            "(38, '/content/drive/MyDrive/Minor Project 3/CADP/Frames/Positive/23.mp4')\n",
            "(39, '/content/drive/MyDrive/Minor Project 3/CADP/Frames/Negative/70.mp4')\n",
            "(40, '/content/drive/MyDrive/Minor Project 3/CADP/Frames/Negative/9.mp4')\n",
            "(41, '/content/drive/MyDrive/Minor Project 3/CADP/Frames/Positive/13.mp4')\n",
            "(42, '/content/drive/MyDrive/Minor Project 3/CADP/Frames/Negative/65.mp4')\n",
            "(43, '/content/drive/MyDrive/Minor Project 3/CADP/Frames/Negative/21.mp4')\n",
            "(44, '/content/drive/MyDrive/Minor Project 3/CADP/Frames/Positive/93.mp4')\n",
            "(45, '/content/drive/MyDrive/Minor Project 3/CADP/Frames/Negative/27.mp4')\n",
            "(46, '/content/drive/MyDrive/Minor Project 3/CADP/Frames/Negative/116.mp4')\n",
            "(47, '/content/drive/MyDrive/Minor Project 3/CADP/Frames/Positive/45.mp4')\n",
            "(48, '/content/drive/MyDrive/Minor Project 3/CADP/Frames/Positive/65.mp4')\n",
            "(49, '/content/drive/MyDrive/Minor Project 3/CADP/Frames/Negative/61.mp4')\n",
            "(50, '/content/drive/MyDrive/Minor Project 3/CADP/Frames/Positive/72.mp4')\n",
            "(51, 99, 144, 256)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "eBkln2q3vfDl"
      },
      "source": [
        "#Saving Numpy Array x_testB\n",
        "os.chdir(\"/content/drive/MyDrive/Minor Project 3/\")\n",
        "np.save('x_testB.npy', x_testB)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "A2F6bwQsaQ49"
      },
      "source": [
        "## Creating and saving x_test"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7na1VHLTaQH6"
      },
      "source": [
        "x_test_batch_list = [x_test[i:i + batch_size] for i in range(0, len(x_test), batch_size)]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "x40QVMopdeUE",
        "outputId": "7d5b7a28-d65f-4194-9ce6-bdef2f4a5ea2"
      },
      "source": [
        "len(x_test_batch_list)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "2"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 23
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "iwXM-DHscByv",
        "outputId": "6ab0677a-85b5-40be-c3cb-59a7aded958e"
      },
      "source": [
        "x_test_batch = []\n",
        "os.chdir(\"/content/drive/MyDrive/Minor Project 3/Model 64/\")\n",
        "for i in range(len(x_test_batch_list)):\n",
        "  x_test_batch = make_dataset(x_test[0:batch_size])\n",
        "  np.save('x_test_batch['+str(i)+'].npy', x_test_batch)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(0, '/content/drive/MyDrive/Minor Project 3/CADP/Frames/Negative/3.mp4')\n",
            "(1, '/content/drive/MyDrive/Minor Project 3/CADP/Frames/Positive/114.mp4')\n",
            "(2, '/content/drive/MyDrive/Minor Project 3/CADP/Frames/Negative/18.mp4')\n",
            "(3, '/content/drive/MyDrive/Minor Project 3/CADP/Frames/Positive/84.mp4')\n",
            "(4, '/content/drive/MyDrive/Minor Project 3/CADP/Frames/Negative/54.mp4')\n",
            "(5, '/content/drive/MyDrive/Minor Project 3/CADP/Frames/Negative/93.mp4')\n",
            "(6, '/content/drive/MyDrive/Minor Project 3/CADP/Frames/Negative/7.mp4')\n",
            "(7, '/content/drive/MyDrive/Minor Project 3/CADP/Frames/Negative/133.mp4')\n",
            "(8, '/content/drive/MyDrive/Minor Project 3/CADP/Frames/Positive/64.mp4')\n",
            "(9, '/content/drive/MyDrive/Minor Project 3/CADP/Frames/Negative/36.mp4')\n",
            "(10, '/content/drive/MyDrive/Minor Project 3/CADP/Frames/Negative/51.mp4')\n",
            "(11, '/content/drive/MyDrive/Minor Project 3/CADP/Frames/Negative/132.mp4')\n",
            "(12, '/content/drive/MyDrive/Minor Project 3/CADP/Frames/Positive/91.mp4')\n",
            "(13, '/content/drive/MyDrive/Minor Project 3/CADP/Frames/Negative/74.mp4')\n",
            "(14, '/content/drive/MyDrive/Minor Project 3/CADP/Frames/Negative/56.mp4')\n",
            "(15, '/content/drive/MyDrive/Minor Project 3/CADP/Frames/Positive/74.mp4')\n",
            "(16, '/content/drive/MyDrive/Minor Project 3/CADP/Frames/Negative/97.mp4')\n",
            "(17, '/content/drive/MyDrive/Minor Project 3/CADP/Frames/Negative/19.mp4')\n",
            "(18, '/content/drive/MyDrive/Minor Project 3/CADP/Frames/Negative/1.mp4')\n",
            "(19, '/content/drive/MyDrive/Minor Project 3/CADP/Frames/Positive/103.mp4')\n",
            "(20, '/content/drive/MyDrive/Minor Project 3/CADP/Frames/Negative/73.mp4')\n",
            "(21, '/content/drive/MyDrive/Minor Project 3/CADP/Frames/Positive/46.mp4')\n",
            "(22, '/content/drive/MyDrive/Minor Project 3/CADP/Frames/Negative/126.mp4')\n",
            "(23, '/content/drive/MyDrive/Minor Project 3/CADP/Frames/Negative/43.mp4')\n",
            "(24, '/content/drive/MyDrive/Minor Project 3/CADP/Frames/Positive/89.mp4')\n",
            "(25, '/content/drive/MyDrive/Minor Project 3/CADP/Frames/Negative/118.mp4')\n",
            "(26, '/content/drive/MyDrive/Minor Project 3/CADP/Frames/Positive/9.mp4')\n",
            "(27, '/content/drive/MyDrive/Minor Project 3/CADP/Frames/Positive/56.mp4')\n",
            "(28, '/content/drive/MyDrive/Minor Project 3/CADP/Frames/Negative/111.mp4')\n",
            "(29, '/content/drive/MyDrive/Minor Project 3/CADP/Frames/Positive/38.mp4')\n",
            "(30, '/content/drive/MyDrive/Minor Project 3/CADP/Frames/Negative/81.mp4')\n",
            "(31, '/content/drive/MyDrive/Minor Project 3/CADP/Frames/Negative/30.mp4')\n",
            "(32, '/content/drive/MyDrive/Minor Project 3/CADP/Frames/Positive/110.mp4')\n",
            "(33, '/content/drive/MyDrive/Minor Project 3/CADP/Frames/Negative/90.mp4')\n",
            "(34, '/content/drive/MyDrive/Minor Project 3/CADP/Frames/Negative/16.mp4')\n",
            "(35, '/content/drive/MyDrive/Minor Project 3/CADP/Frames/Negative/49.mp4')\n",
            "(36, '/content/drive/MyDrive/Minor Project 3/CADP/Frames/Negative/72.mp4')\n",
            "(37, '/content/drive/MyDrive/Minor Project 3/CADP/Frames/Positive/6.mp4')\n",
            "(38, '/content/drive/MyDrive/Minor Project 3/CADP/Frames/Positive/23.mp4')\n",
            "(39, '/content/drive/MyDrive/Minor Project 3/CADP/Frames/Negative/76.mp4')\n",
            "(40, '/content/drive/MyDrive/Minor Project 3/CADP/Frames/Negative/31.mp4')\n",
            "(41, '/content/drive/MyDrive/Minor Project 3/CADP/Frames/Positive/13.mp4')\n",
            "(42, '/content/drive/MyDrive/Minor Project 3/CADP/Frames/Negative/71.mp4')\n",
            "(43, '/content/drive/MyDrive/Minor Project 3/CADP/Frames/Negative/64.mp4')\n",
            "(44, '/content/drive/MyDrive/Minor Project 3/CADP/Frames/Positive/93.mp4')\n",
            "(45, '/content/drive/MyDrive/Minor Project 3/CADP/Frames/Negative/33.mp4')\n",
            "(46, '/content/drive/MyDrive/Minor Project 3/CADP/Frames/Negative/107.mp4')\n",
            "(47, '/content/drive/MyDrive/Minor Project 3/CADP/Frames/Positive/45.mp4')\n",
            "(48, '/content/drive/MyDrive/Minor Project 3/CADP/Frames/Positive/65.mp4')\n",
            "(49, '/content/drive/MyDrive/Minor Project 3/CADP/Frames/Negative/67.mp4')\n",
            "(50, '/content/drive/MyDrive/Minor Project 3/CADP/Frames/Positive/72.mp4')\n",
            "(51, '/content/drive/MyDrive/Minor Project 3/CADP/Frames/Negative/11.mp4')\n",
            "(52, '/content/drive/MyDrive/Minor Project 3/CADP/Frames/Negative/22.mp4')\n",
            "(53, '/content/drive/MyDrive/Minor Project 3/CADP/Frames/Positive/77.mp4')\n",
            "(54, '/content/drive/MyDrive/Minor Project 3/CADP/Frames/Positive/60.mp4')\n",
            "(55, '/content/drive/MyDrive/Minor Project 3/CADP/Frames/Negative/88.mp4')\n",
            "(56, '/content/drive/MyDrive/Minor Project 3/CADP/Frames/Negative/138.mp4')\n",
            "(57, '/content/drive/MyDrive/Minor Project 3/CADP/Frames/Positive/19.mp4')\n",
            "(58, '/content/drive/MyDrive/Minor Project 3/CADP/Frames/Negative/105.mp4')\n",
            "(59, '/content/drive/MyDrive/Minor Project 3/CADP/Frames/Positive/16.mp4')\n",
            "(60, '/content/drive/MyDrive/Minor Project 3/CADP/Frames/Negative/55.mp4')\n",
            "(61, '/content/drive/MyDrive/Minor Project 3/CADP/Frames/Positive/75.mp4')\n",
            "(62, '/content/drive/MyDrive/Minor Project 3/CADP/Frames/Positive/8.mp4')\n",
            "(63, '/content/drive/MyDrive/Minor Project 3/CADP/Frames/Positive/94.mp4')\n",
            "(64, 99, 144, 256)\n",
            "(0, '/content/drive/MyDrive/Minor Project 3/CADP/Frames/Negative/3.mp4')\n",
            "(1, '/content/drive/MyDrive/Minor Project 3/CADP/Frames/Positive/114.mp4')\n",
            "(2, '/content/drive/MyDrive/Minor Project 3/CADP/Frames/Negative/18.mp4')\n",
            "(3, '/content/drive/MyDrive/Minor Project 3/CADP/Frames/Positive/84.mp4')\n",
            "(4, '/content/drive/MyDrive/Minor Project 3/CADP/Frames/Negative/54.mp4')\n",
            "(5, '/content/drive/MyDrive/Minor Project 3/CADP/Frames/Negative/93.mp4')\n",
            "(6, '/content/drive/MyDrive/Minor Project 3/CADP/Frames/Negative/7.mp4')\n",
            "(7, '/content/drive/MyDrive/Minor Project 3/CADP/Frames/Negative/133.mp4')\n",
            "(8, '/content/drive/MyDrive/Minor Project 3/CADP/Frames/Positive/64.mp4')\n",
            "(9, '/content/drive/MyDrive/Minor Project 3/CADP/Frames/Negative/36.mp4')\n",
            "(10, '/content/drive/MyDrive/Minor Project 3/CADP/Frames/Negative/51.mp4')\n",
            "(11, '/content/drive/MyDrive/Minor Project 3/CADP/Frames/Negative/132.mp4')\n",
            "(12, '/content/drive/MyDrive/Minor Project 3/CADP/Frames/Positive/91.mp4')\n",
            "(13, '/content/drive/MyDrive/Minor Project 3/CADP/Frames/Negative/74.mp4')\n",
            "(14, '/content/drive/MyDrive/Minor Project 3/CADP/Frames/Negative/56.mp4')\n",
            "(15, '/content/drive/MyDrive/Minor Project 3/CADP/Frames/Positive/74.mp4')\n",
            "(16, '/content/drive/MyDrive/Minor Project 3/CADP/Frames/Negative/97.mp4')\n",
            "(17, '/content/drive/MyDrive/Minor Project 3/CADP/Frames/Negative/19.mp4')\n",
            "(18, '/content/drive/MyDrive/Minor Project 3/CADP/Frames/Negative/1.mp4')\n",
            "(19, '/content/drive/MyDrive/Minor Project 3/CADP/Frames/Positive/103.mp4')\n",
            "(20, '/content/drive/MyDrive/Minor Project 3/CADP/Frames/Negative/73.mp4')\n",
            "(21, '/content/drive/MyDrive/Minor Project 3/CADP/Frames/Positive/46.mp4')\n",
            "(22, '/content/drive/MyDrive/Minor Project 3/CADP/Frames/Negative/126.mp4')\n",
            "(23, '/content/drive/MyDrive/Minor Project 3/CADP/Frames/Negative/43.mp4')\n",
            "(24, '/content/drive/MyDrive/Minor Project 3/CADP/Frames/Positive/89.mp4')\n",
            "(25, '/content/drive/MyDrive/Minor Project 3/CADP/Frames/Negative/118.mp4')\n",
            "(26, '/content/drive/MyDrive/Minor Project 3/CADP/Frames/Positive/9.mp4')\n",
            "(27, '/content/drive/MyDrive/Minor Project 3/CADP/Frames/Positive/56.mp4')\n",
            "(28, '/content/drive/MyDrive/Minor Project 3/CADP/Frames/Negative/111.mp4')\n",
            "(29, '/content/drive/MyDrive/Minor Project 3/CADP/Frames/Positive/38.mp4')\n",
            "(30, '/content/drive/MyDrive/Minor Project 3/CADP/Frames/Negative/81.mp4')\n",
            "(31, '/content/drive/MyDrive/Minor Project 3/CADP/Frames/Negative/30.mp4')\n",
            "(32, '/content/drive/MyDrive/Minor Project 3/CADP/Frames/Positive/110.mp4')\n",
            "(33, '/content/drive/MyDrive/Minor Project 3/CADP/Frames/Negative/90.mp4')\n",
            "(34, '/content/drive/MyDrive/Minor Project 3/CADP/Frames/Negative/16.mp4')\n",
            "(35, '/content/drive/MyDrive/Minor Project 3/CADP/Frames/Negative/49.mp4')\n",
            "(36, '/content/drive/MyDrive/Minor Project 3/CADP/Frames/Negative/72.mp4')\n",
            "(37, '/content/drive/MyDrive/Minor Project 3/CADP/Frames/Positive/6.mp4')\n",
            "(38, '/content/drive/MyDrive/Minor Project 3/CADP/Frames/Positive/23.mp4')\n",
            "(39, '/content/drive/MyDrive/Minor Project 3/CADP/Frames/Negative/76.mp4')\n",
            "(40, '/content/drive/MyDrive/Minor Project 3/CADP/Frames/Negative/31.mp4')\n",
            "(41, '/content/drive/MyDrive/Minor Project 3/CADP/Frames/Positive/13.mp4')\n",
            "(42, '/content/drive/MyDrive/Minor Project 3/CADP/Frames/Negative/71.mp4')\n",
            "(43, '/content/drive/MyDrive/Minor Project 3/CADP/Frames/Negative/64.mp4')\n",
            "(44, '/content/drive/MyDrive/Minor Project 3/CADP/Frames/Positive/93.mp4')\n",
            "(45, '/content/drive/MyDrive/Minor Project 3/CADP/Frames/Negative/33.mp4')\n",
            "(46, '/content/drive/MyDrive/Minor Project 3/CADP/Frames/Negative/107.mp4')\n",
            "(47, '/content/drive/MyDrive/Minor Project 3/CADP/Frames/Positive/45.mp4')\n",
            "(48, '/content/drive/MyDrive/Minor Project 3/CADP/Frames/Positive/65.mp4')\n",
            "(49, '/content/drive/MyDrive/Minor Project 3/CADP/Frames/Negative/67.mp4')\n",
            "(50, '/content/drive/MyDrive/Minor Project 3/CADP/Frames/Positive/72.mp4')\n",
            "(51, '/content/drive/MyDrive/Minor Project 3/CADP/Frames/Negative/11.mp4')\n",
            "(52, '/content/drive/MyDrive/Minor Project 3/CADP/Frames/Negative/22.mp4')\n",
            "(53, '/content/drive/MyDrive/Minor Project 3/CADP/Frames/Positive/77.mp4')\n",
            "(54, '/content/drive/MyDrive/Minor Project 3/CADP/Frames/Positive/60.mp4')\n",
            "(55, '/content/drive/MyDrive/Minor Project 3/CADP/Frames/Negative/88.mp4')\n",
            "(56, '/content/drive/MyDrive/Minor Project 3/CADP/Frames/Negative/138.mp4')\n",
            "(57, '/content/drive/MyDrive/Minor Project 3/CADP/Frames/Positive/19.mp4')\n",
            "(58, '/content/drive/MyDrive/Minor Project 3/CADP/Frames/Negative/105.mp4')\n",
            "(59, '/content/drive/MyDrive/Minor Project 3/CADP/Frames/Positive/16.mp4')\n",
            "(60, '/content/drive/MyDrive/Minor Project 3/CADP/Frames/Negative/55.mp4')\n",
            "(61, '/content/drive/MyDrive/Minor Project 3/CADP/Frames/Positive/75.mp4')\n",
            "(62, '/content/drive/MyDrive/Minor Project 3/CADP/Frames/Positive/8.mp4')\n",
            "(63, '/content/drive/MyDrive/Minor Project 3/CADP/Frames/Positive/94.mp4')\n",
            "(64, 99, 144, 256)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "soRflAJIaWmN"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "L73Vx1kT-z0P"
      },
      "source": [
        "## Loading x_testA and x_testB from .npy files"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "R6Jk1Yz9-ziy",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "4f07af7e-f0c1-4183-8dd4-05549ab5a71a"
      },
      "source": [
        "os.chdir('/content/drive/MyDrive/Minor Project 3/')\n",
        "x_testA = np.load('x_testA.npy')\n",
        "x_testA.shape"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(52, 99, 144, 256)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 7
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LvefH818_yp8",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "97ea5b4f-59da-4625-8759-cc935ae6c577"
      },
      "source": [
        "x_testB = np.load('x_testB.npy')\n",
        "x_testB.shape"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(51, 99, 144, 256)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 8
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FVu-6i-Ya11R"
      },
      "source": [
        "#x_test\n",
        "x_test = np.load('x_test.npy')\n",
        "x_test.shape"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "h_oFFTA6AECx"
      },
      "source": [
        "# Model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7er9Livcknjg"
      },
      "source": [
        "os.chdir(\"/content/drive/MyDrive/Minor Project 3/\")\n",
        "i=0; filepath='HRNN_pretrained_model.hdf5'\n",
        "checkpoint = ModelCheckpoint(filepath, monitor='val_acc', verbose=1, save_best_only=True, mode='max')\n",
        "callbacks_list = [checkpoint]\n",
        "\n",
        "np.random.seed(1642)"
      ],
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Tg-bBPNBV73n"
      },
      "source": [
        "for i in range(0, epochs): \n",
        "  c = list(zip(x_train, y_train)) \n",
        "  random.shuffle(c) \n",
        "\n",
        "x_shuff, y_shuff = zip(*c) \n",
        "x_shuff = np.array(x_shuff)\n",
        "y_shuff=np.array(y_shuff) \n",
        "\n",
        "x_batch = [x_shuff[i:i + batch_size] for i in range(0, len(x_shuff), batch_size)] \n",
        "y_batch = [y_shuff[i:i + batch_size] for i in range(0, len(x_shuff), batch_size)] "
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WaSqdLKpwCNz"
      },
      "source": [
        "print('x_batch length = ',len(x_batch))\n",
        "print('y_batch length = ',len(y_batch))\n",
        "\n",
        "print('x_batch[0] length = ',len(x_batch[0]))\n",
        "print('y_batch[0] length = ',len(x_batch[0]))\n",
        "\n",
        "print('x_testB type = ',type(x_testB))\n",
        "print('y_testB type = ',type(y_testB))\n",
        "\n",
        "print('y_testB length = ', len(y_testB))\n",
        "print('x_testB shape = ', x_testB.shape)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zeOBqfDOV7yz",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "89d9408e-ada7-42d6-8aa1-619bc46f9c6c"
      },
      "source": [
        "os.chdir(\"/content/drive/MyDrive/Minor Project 3/Model 64/\")\n",
        "for i in range(len(x_batch)):\n",
        "  xx = make_dataset(x_batch[i])\n",
        "  np.save('xx['+str(i)+'].npy', xx)\n",
        "  yy = y_batch[i]\n",
        "  np.save('yy['+str(i)+'].npy', yy)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(0, '/content/drive/MyDrive/Minor Project 3/CADP/Frames/Positive/50.mp4')\n",
            "(1, '/content/drive/MyDrive/Minor Project 3/CADP/Frames/Negative/12.mp4')\n",
            "(2, '/content/drive/MyDrive/Minor Project 3/CADP/Frames/Positive/88.mp4')\n",
            "(3, '/content/drive/MyDrive/Minor Project 3/CADP/Frames/Positive/30.mp4')\n",
            "(4, '/content/drive/MyDrive/Minor Project 3/CADP/Frames/Positive/7.mp4')\n",
            "(5, '/content/drive/MyDrive/Minor Project 3/CADP/Frames/Positive/85.mp4')\n",
            "(6, '/content/drive/MyDrive/Minor Project 3/CADP/Frames/Negative/108.mp4')\n",
            "(7, '/content/drive/MyDrive/Minor Project 3/CADP/Frames/Negative/140.mp4')\n",
            "(8, '/content/drive/MyDrive/Minor Project 3/CADP/Frames/Negative/78.mp4')\n",
            "(9, '/content/drive/MyDrive/Minor Project 3/CADP/Frames/Negative/128.mp4')\n",
            "(10, '/content/drive/MyDrive/Minor Project 3/CADP/Frames/Positive/48.mp4')\n",
            "(11, '/content/drive/MyDrive/Minor Project 3/CADP/Frames/Positive/100.mp4')\n",
            "(12, '/content/drive/MyDrive/Minor Project 3/CADP/Frames/Negative/47.mp4')\n",
            "(13, '/content/drive/MyDrive/Minor Project 3/CADP/Frames/Positive/11.mp4')\n",
            "(14, '/content/drive/MyDrive/Minor Project 3/CADP/Frames/Negative/79.mp4')\n",
            "(15, '/content/drive/MyDrive/Minor Project 3/CADP/Frames/Negative/77.mp4')\n",
            "(16, '/content/drive/MyDrive/Minor Project 3/CADP/Frames/Positive/98.mp4')\n",
            "(17, '/content/drive/MyDrive/Minor Project 3/CADP/Frames/Negative/106.mp4')\n",
            "(18, '/content/drive/MyDrive/Minor Project 3/CADP/Frames/Negative/87.mp4')\n",
            "(19, '/content/drive/MyDrive/Minor Project 3/CADP/Frames/Positive/99.mp4')\n",
            "(20, '/content/drive/MyDrive/Minor Project 3/CADP/Frames/Negative/25.mp4')\n",
            "(21, '/content/drive/MyDrive/Minor Project 3/CADP/Frames/Positive/28.mp4')\n",
            "(22, '/content/drive/MyDrive/Minor Project 3/CADP/Frames/Negative/113.mp4')\n",
            "(23, '/content/drive/MyDrive/Minor Project 3/CADP/Frames/Positive/26.mp4')\n",
            "(24, '/content/drive/MyDrive/Minor Project 3/CADP/Frames/Positive/21.mp4')\n",
            "(25, '/content/drive/MyDrive/Minor Project 3/CADP/Frames/Positive/115.mp4')\n",
            "(26, '/content/drive/MyDrive/Minor Project 3/CADP/Frames/Positive/70.mp4')\n",
            "(27, '/content/drive/MyDrive/Minor Project 3/CADP/Frames/Negative/44.mp4')\n",
            "(28, '/content/drive/MyDrive/Minor Project 3/CADP/Frames/Negative/100.mp4')\n",
            "(29, '/content/drive/MyDrive/Minor Project 3/CADP/Frames/Negative/102.mp4')\n",
            "(30, '/content/drive/MyDrive/Minor Project 3/CADP/Frames/Negative/29.mp4')\n",
            "(31, '/content/drive/MyDrive/Minor Project 3/CADP/Frames/Negative/114.mp4')\n",
            "(32, '/content/drive/MyDrive/Minor Project 3/CADP/Frames/Positive/37.mp4')\n",
            "(33, '/content/drive/MyDrive/Minor Project 3/CADP/Frames/Positive/29.mp4')\n",
            "(34, '/content/drive/MyDrive/Minor Project 3/CADP/Frames/Negative/70.mp4')\n",
            "(35, '/content/drive/MyDrive/Minor Project 3/CADP/Frames/Negative/104.mp4')\n",
            "(36, '/content/drive/MyDrive/Minor Project 3/CADP/Frames/Negative/110.mp4')\n",
            "(37, '/content/drive/MyDrive/Minor Project 3/CADP/Frames/Positive/43.mp4')\n",
            "(38, '/content/drive/MyDrive/Minor Project 3/CADP/Frames/Positive/40.mp4')\n",
            "(39, '/content/drive/MyDrive/Minor Project 3/CADP/Frames/Positive/107.mp4')\n",
            "(40, '/content/drive/MyDrive/Minor Project 3/CADP/Frames/Positive/33.mp4')\n",
            "(41, '/content/drive/MyDrive/Minor Project 3/CADP/Frames/Negative/135.mp4')\n",
            "(42, '/content/drive/MyDrive/Minor Project 3/CADP/Frames/Positive/36.mp4')\n",
            "(43, '/content/drive/MyDrive/Minor Project 3/CADP/Frames/Positive/71.mp4')\n",
            "(44, '/content/drive/MyDrive/Minor Project 3/CADP/Frames/Positive/49.mp4')\n",
            "(45, '/content/drive/MyDrive/Minor Project 3/CADP/Frames/Positive/35.mp4')\n",
            "(46, '/content/drive/MyDrive/Minor Project 3/CADP/Frames/Positive/10.mp4')\n",
            "(47, '/content/drive/MyDrive/Minor Project 3/CADP/Frames/Positive/18.mp4')\n",
            "(48, '/content/drive/MyDrive/Minor Project 3/CADP/Frames/Positive/101.mp4')\n",
            "(49, '/content/drive/MyDrive/Minor Project 3/CADP/Frames/Positive/52.mp4')\n",
            "(50, '/content/drive/MyDrive/Minor Project 3/CADP/Frames/Negative/89.mp4')\n",
            "(51, '/content/drive/MyDrive/Minor Project 3/CADP/Frames/Positive/81.mp4')\n",
            "(52, '/content/drive/MyDrive/Minor Project 3/CADP/Frames/Negative/59.mp4')\n",
            "(53, '/content/drive/MyDrive/Minor Project 3/CADP/Frames/Negative/131.mp4')\n",
            "(54, '/content/drive/MyDrive/Minor Project 3/CADP/Frames/Positive/59.mp4')\n",
            "(55, '/content/drive/MyDrive/Minor Project 3/CADP/Frames/Positive/24.mp4')\n",
            "(56, '/content/drive/MyDrive/Minor Project 3/CADP/Frames/Positive/97.mp4')\n",
            "(57, '/content/drive/MyDrive/Minor Project 3/CADP/Frames/Negative/95.mp4')\n",
            "(58, '/content/drive/MyDrive/Minor Project 3/CADP/Frames/Positive/66.mp4')\n",
            "(59, '/content/drive/MyDrive/Minor Project 3/CADP/Frames/Negative/98.mp4')\n",
            "(60, '/content/drive/MyDrive/Minor Project 3/CADP/Frames/Negative/52.mp4')\n",
            "(61, '/content/drive/MyDrive/Minor Project 3/CADP/Frames/Negative/20.mp4')\n",
            "(62, '/content/drive/MyDrive/Minor Project 3/CADP/Frames/Positive/22.mp4')\n",
            "(63, '/content/drive/MyDrive/Minor Project 3/CADP/Frames/Positive/2.mp4')\n",
            "(64, 99, 144, 256)\n",
            "(0, '/content/drive/MyDrive/Minor Project 3/CADP/Frames/Negative/45.mp4')\n",
            "(1, '/content/drive/MyDrive/Minor Project 3/CADP/Frames/Negative/63.mp4')\n",
            "(2, '/content/drive/MyDrive/Minor Project 3/CADP/Frames/Negative/14.mp4')\n",
            "(3, '/content/drive/MyDrive/Minor Project 3/CADP/Frames/Positive/105.mp4')\n",
            "(4, '/content/drive/MyDrive/Minor Project 3/CADP/Frames/Negative/124.mp4')\n",
            "(5, '/content/drive/MyDrive/Minor Project 3/CADP/Frames/Negative/68.mp4')\n",
            "(6, '/content/drive/MyDrive/Minor Project 3/CADP/Frames/Positive/108.mp4')\n",
            "(7, '/content/drive/MyDrive/Minor Project 3/CADP/Frames/Negative/94.mp4')\n",
            "(8, '/content/drive/MyDrive/Minor Project 3/CADP/Frames/Negative/83.mp4')\n",
            "(9, '/content/drive/MyDrive/Minor Project 3/CADP/Frames/Negative/96.mp4')\n",
            "(10, '/content/drive/MyDrive/Minor Project 3/CADP/Frames/Negative/17.mp4')\n",
            "(11, '/content/drive/MyDrive/Minor Project 3/CADP/Frames/Negative/123.mp4')\n",
            "(12, '/content/drive/MyDrive/Minor Project 3/CADP/Frames/Negative/134.mp4')\n",
            "(13, '/content/drive/MyDrive/Minor Project 3/CADP/Frames/Negative/21.mp4')\n",
            "(14, '/content/drive/MyDrive/Minor Project 3/CADP/Frames/Negative/37.mp4')\n",
            "(15, '/content/drive/MyDrive/Minor Project 3/CADP/Frames/Negative/109.mp4')\n",
            "(16, '/content/drive/MyDrive/Minor Project 3/CADP/Frames/Negative/38.mp4')\n",
            "(17, '/content/drive/MyDrive/Minor Project 3/CADP/Frames/Positive/104.mp4')\n",
            "(18, '/content/drive/MyDrive/Minor Project 3/CADP/Frames/Negative/115.mp4')\n",
            "(19, '/content/drive/MyDrive/Minor Project 3/CADP/Frames/Negative/35.mp4')\n",
            "(20, '/content/drive/MyDrive/Minor Project 3/CADP/Frames/Positive/51.mp4')\n",
            "(21, '/content/drive/MyDrive/Minor Project 3/CADP/Frames/Negative/5.mp4')\n",
            "(22, '/content/drive/MyDrive/Minor Project 3/CADP/Frames/Negative/10.mp4')\n",
            "(23, '/content/drive/MyDrive/Minor Project 3/CADP/Frames/Positive/4.mp4')\n",
            "(24, '/content/drive/MyDrive/Minor Project 3/CADP/Frames/Negative/120.mp4')\n",
            "(25, '/content/drive/MyDrive/Minor Project 3/CADP/Frames/Positive/73.mp4')\n",
            "(26, '/content/drive/MyDrive/Minor Project 3/CADP/Frames/Positive/80.mp4')\n",
            "(27, '/content/drive/MyDrive/Minor Project 3/CADP/Frames/Negative/80.mp4')\n",
            "(28, '/content/drive/MyDrive/Minor Project 3/CADP/Frames/Negative/4.mp4')\n",
            "(29, '/content/drive/MyDrive/Minor Project 3/CADP/Frames/Negative/66.mp4')\n",
            "(30, '/content/drive/MyDrive/Minor Project 3/CADP/Frames/Negative/13.mp4')\n",
            "(31, '/content/drive/MyDrive/Minor Project 3/CADP/Frames/Negative/57.mp4')\n",
            "(32, '/content/drive/MyDrive/Minor Project 3/CADP/Frames/Negative/46.mp4')\n",
            "(33, '/content/drive/MyDrive/Minor Project 3/CADP/Frames/Positive/32.mp4')\n",
            "(34, '/content/drive/MyDrive/Minor Project 3/CADP/Frames/Negative/65.mp4')\n",
            "(35, '/content/drive/MyDrive/Minor Project 3/CADP/Frames/Negative/24.mp4')\n",
            "(36, '/content/drive/MyDrive/Minor Project 3/CADP/Frames/Positive/3.mp4')\n",
            "(37, '/content/drive/MyDrive/Minor Project 3/CADP/Frames/Negative/41.mp4')\n",
            "(38, '/content/drive/MyDrive/Minor Project 3/CADP/Frames/Negative/82.mp4')\n",
            "(39, '/content/drive/MyDrive/Minor Project 3/CADP/Frames/Negative/8.mp4')\n",
            "(40, '/content/drive/MyDrive/Minor Project 3/CADP/Frames/Positive/106.mp4')\n",
            "(41, '/content/drive/MyDrive/Minor Project 3/CADP/Frames/Positive/39.mp4')\n",
            "(42, '/content/drive/MyDrive/Minor Project 3/CADP/Frames/Negative/130.mp4')\n",
            "(43, '/content/drive/MyDrive/Minor Project 3/CADP/Frames/Negative/85.mp4')\n",
            "(44, '/content/drive/MyDrive/Minor Project 3/CADP/Frames/Positive/68.mp4')\n",
            "(45, '/content/drive/MyDrive/Minor Project 3/CADP/Frames/Negative/28.mp4')\n",
            "(46, '/content/drive/MyDrive/Minor Project 3/CADP/Frames/Positive/54.mp4')\n",
            "(47, '/content/drive/MyDrive/Minor Project 3/CADP/Frames/Negative/91.mp4')\n",
            "(48, '/content/drive/MyDrive/Minor Project 3/CADP/Frames/Negative/119.mp4')\n",
            "(49, '/content/drive/MyDrive/Minor Project 3/CADP/Frames/Negative/48.mp4')\n",
            "(50, '/content/drive/MyDrive/Minor Project 3/CADP/Frames/Negative/62.mp4')\n",
            "(51, '/content/drive/MyDrive/Minor Project 3/CADP/Frames/Positive/83.mp4')\n",
            "(52, '/content/drive/MyDrive/Minor Project 3/CADP/Frames/Negative/122.mp4')\n",
            "(53, '/content/drive/MyDrive/Minor Project 3/CADP/Frames/Negative/27.mp4')\n",
            "(54, '/content/drive/MyDrive/Minor Project 3/CADP/Frames/Negative/121.mp4')\n",
            "(55, '/content/drive/MyDrive/Minor Project 3/CADP/Frames/Negative/50.mp4')\n",
            "(56, '/content/drive/MyDrive/Minor Project 3/CADP/Frames/Positive/44.mp4')\n",
            "(57, '/content/drive/MyDrive/Minor Project 3/CADP/Frames/Positive/47.mp4')\n",
            "(58, '/content/drive/MyDrive/Minor Project 3/CADP/Frames/Negative/32.mp4')\n",
            "(59, '/content/drive/MyDrive/Minor Project 3/CADP/Frames/Negative/125.mp4')\n",
            "(60, '/content/drive/MyDrive/Minor Project 3/CADP/Frames/Negative/116.mp4')\n",
            "(61, '/content/drive/MyDrive/Minor Project 3/CADP/Frames/Negative/99.mp4')\n",
            "(62, '/content/drive/MyDrive/Minor Project 3/CADP/Frames/Negative/15.mp4')\n",
            "(63, '/content/drive/MyDrive/Minor Project 3/CADP/Frames/Negative/84.mp4')\n",
            "(64, 99, 144, 256)\n",
            "(0, '/content/drive/MyDrive/Minor Project 3/CADP/Frames/Negative/60.mp4')\n",
            "(1, '/content/drive/MyDrive/Minor Project 3/CADP/Frames/Positive/82.mp4')\n",
            "(2, '/content/drive/MyDrive/Minor Project 3/CADP/Frames/Negative/136.mp4')\n",
            "(3, '/content/drive/MyDrive/Minor Project 3/CADP/Frames/Negative/92.mp4')\n",
            "(4, '/content/drive/MyDrive/Minor Project 3/CADP/Frames/Positive/42.mp4')\n",
            "(5, '/content/drive/MyDrive/Minor Project 3/CADP/Frames/Negative/53.mp4')\n",
            "(6, '/content/drive/MyDrive/Minor Project 3/CADP/Frames/Negative/34.mp4')\n",
            "(7, '/content/drive/MyDrive/Minor Project 3/CADP/Frames/Positive/63.mp4')\n",
            "(8, '/content/drive/MyDrive/Minor Project 3/CADP/Frames/Negative/9.mp4')\n",
            "(9, '/content/drive/MyDrive/Minor Project 3/CADP/Frames/Positive/78.mp4')\n",
            "(10, '/content/drive/MyDrive/Minor Project 3/CADP/Frames/Positive/102.mp4')\n",
            "(11, '/content/drive/MyDrive/Minor Project 3/CADP/Frames/Positive/111.mp4')\n",
            "(12, '/content/drive/MyDrive/Minor Project 3/CADP/Frames/Positive/87.mp4')\n",
            "(13, '/content/drive/MyDrive/Minor Project 3/CADP/Frames/Positive/15.mp4')\n",
            "(14, '/content/drive/MyDrive/Minor Project 3/CADP/Frames/Positive/12.mp4')\n",
            "(15, '/content/drive/MyDrive/Minor Project 3/CADP/Frames/Positive/112.mp4')\n",
            "(16, '/content/drive/MyDrive/Minor Project 3/CADP/Frames/Negative/117.mp4')\n",
            "(17, '/content/drive/MyDrive/Minor Project 3/CADP/Frames/Negative/39.mp4')\n",
            "(18, '/content/drive/MyDrive/Minor Project 3/CADP/Frames/Positive/58.mp4')\n",
            "(19, '/content/drive/MyDrive/Minor Project 3/CADP/Frames/Positive/92.mp4')\n",
            "(20, '/content/drive/MyDrive/Minor Project 3/CADP/Frames/Positive/79.mp4')\n",
            "(21, '/content/drive/MyDrive/Minor Project 3/CADP/Frames/Positive/113.mp4')\n",
            "(22, '/content/drive/MyDrive/Minor Project 3/CADP/Frames/Positive/86.mp4')\n",
            "(23, '/content/drive/MyDrive/Minor Project 3/CADP/Frames/Negative/137.mp4')\n",
            "(24, '/content/drive/MyDrive/Minor Project 3/CADP/Frames/Positive/69.mp4')\n",
            "(25, 99, 144, 256)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "m3NxTxCee--z",
        "outputId": "6ce46150-5a3a-43a4-fcce-88c6aecabdbd"
      },
      "source": [
        "os.chdir(\"/content/drive/MyDrive/Minor Project 3/Model 64/\")\n",
        "y_test_temp = [y_test[i:i + batch_size] for i in range(0, len(y_test), batch_size)] \n",
        "y_testB_temp = np.array(y_test_temp)\n",
        "np.save('y_test_temp.npy',y_test_temp)"
      ],
      "execution_count": 28,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:3: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray\n",
            "  This is separate from the ipykernel package so we can avoid doing imports until\n",
            "/usr/local/lib/python3.7/dist-packages/numpy/core/_asarray.py:136: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray\n",
            "  return array(a, dtype, copy=False, order=order, subok=True)\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dm1JpVbTfJsA"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kFZrZzGesNxg"
      },
      "source": [
        "## Saving xx and yy"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "K9H3r9fvcz92"
      },
      "source": [
        "os.chdir(\"/content/drive/MyDrive/Minor Project 3/\")\n",
        "np.save('xx.npy',xx)\n",
        "np.save('yy.npy', yy)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Gd8pk-UvsQ8z"
      },
      "source": [
        "## Loading xx and yy"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NghursqXsHe5"
      },
      "source": [
        "os.chdir(\"/content/drive/MyDrive/Minor Project 3/\")\n",
        "xx = np.load('xx.npy')"
      ],
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TuRn8gAHWWpA"
      },
      "source": [
        "yy = np.load('yy.npy')"
      ],
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zG4L6jJEXJJE",
        "outputId": "8661f70f-5d84-4e99-f24e-2b2d8d095815"
      },
      "source": [
        "xx.shape"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(153, 99, 144, 256)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 26
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_pjUJfODXNTb",
        "outputId": "36339127-7fb9-4d9e-a3e9-4bfe091014b1"
      },
      "source": [
        "yy.shape"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(153, 2)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 27
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "KMl2pG3MQ-jV",
        "outputId": "3739a0ca-eeae-40e3-bb6c-1399f4a307cc"
      },
      "source": [
        ""
      ],
      "execution_count": 32,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[0.45687492, 0.46596604, 0.46131419, ..., 0.37506377, 0.47633568,\n",
              "        0.44492756],\n",
              "       [0.43551472, 0.45259789, 0.45408914, ..., 0.34043982, 0.4959389 ,\n",
              "        0.4573413 ],\n",
              "       [0.39686321, 0.41238957, 0.42706992, ..., 0.29875568, 0.45679521,\n",
              "        0.46469144],\n",
              "       ...,\n",
              "       [0.44584216, 0.4547345 , 0.44493554, ..., 0.12415221, 0.12160724,\n",
              "        0.12077415],\n",
              "       [0.43105078, 0.43858168, 0.43297461, ..., 0.11959112, 0.11859738,\n",
              "        0.11858358],\n",
              "       [0.4220722 , 0.43027833, 0.42623077, ..., 0.11680954, 0.11569594,\n",
              "        0.11569391]])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 32
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OuTCXiX9eNWi"
      },
      "source": [
        "y_test_temp1 = np.array(y_test[0:batch_size])\n",
        "y_test_temp2 = np.array(y_test[38:102])\n",
        "y_test_np = np.concatenate((y_test_temp1, y_test_temp2), axis = 0)"
      ],
      "execution_count": 51,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "77wXErXOTiSB"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MvG6lz-2eesS"
      },
      "source": [
        "np.save('y_test_np.npy',y_test_np)"
      ],
      "execution_count": 52,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LvIKg8YLbOb3",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "3aac2c13-692c-4c65-ecc6-03e1a391fce3"
      },
      "source": [
        "y_test = np.load('y_test_np.npy')\n",
        "y_test.shape"
      ],
      "execution_count": 53,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(128, 2)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 53
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xXou-V-wfsbW"
      },
      "source": [
        "# Model 64"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ueNaY3Y8H4i8",
        "outputId": "6886dc97-fc43-468f-fad4-8a0cebb0c20e"
      },
      "source": [
        "os.chdir(\"/content/drive/MyDrive/Minor Project 3/Model 64/\")\n",
        "for i in range(3):\n",
        "  xx = np.load('xx['+str(i)+'].npy')\n",
        "  yy = np.load('yy['+str(i)+'].npy')\n",
        "\n",
        "  model.fit(xx, yy, batch_size=len(xx),epochs=30, callbacks=callbacks_list)\n",
        "  #model.fit(xx, yy, batch_size=len(xx),epochs=30)\n",
        "\n",
        "  del xx\n",
        "  del yy\n",
        "\n",
        "  modelfilename = '/content/drive/MyDrive/Minor Project 3/Checkpoints/model_64['+str(i)+'].h5' \n",
        "  model.save_weights(modelfilename)"
      ],
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/30\n",
            "1/1 [==============================] - 1s 854ms/step - loss: 0.6766 - accuracy: 0.6562\n",
            "WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n",
            "Epoch 2/30\n",
            "1/1 [==============================] - 1s 502ms/step - loss: 0.5804 - accuracy: 0.7188\n",
            "WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n",
            "Epoch 3/30\n",
            "1/1 [==============================] - 1s 539ms/step - loss: 0.5659 - accuracy: 0.7344\n",
            "WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n",
            "Epoch 4/30\n",
            "1/1 [==============================] - 0s 438ms/step - loss: 0.7089 - accuracy: 0.4844\n",
            "WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n",
            "Epoch 5/30\n",
            "1/1 [==============================] - 1s 592ms/step - loss: 0.6831 - accuracy: 0.5156\n",
            "WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n",
            "Epoch 6/30\n",
            "1/1 [==============================] - 0s 487ms/step - loss: 0.6270 - accuracy: 0.6562\n",
            "WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n",
            "Epoch 7/30\n",
            "1/1 [==============================] - 0s 485ms/step - loss: 0.6211 - accuracy: 0.6094\n",
            "WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n",
            "Epoch 8/30\n",
            "1/1 [==============================] - 0s 481ms/step - loss: 0.6757 - accuracy: 0.4844\n",
            "WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n",
            "Epoch 9/30\n",
            "1/1 [==============================] - 1s 536ms/step - loss: 0.6373 - accuracy: 0.6250\n",
            "WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n",
            "Epoch 10/30\n",
            "1/1 [==============================] - 0s 500ms/step - loss: 0.6190 - accuracy: 0.6094\n",
            "WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n",
            "Epoch 11/30\n",
            "1/1 [==============================] - 0s 500ms/step - loss: 0.6020 - accuracy: 0.6406\n",
            "WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n",
            "Epoch 12/30\n",
            "1/1 [==============================] - 0s 484ms/step - loss: 0.6135 - accuracy: 0.6250\n",
            "WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n",
            "Epoch 13/30\n",
            "1/1 [==============================] - 1s 506ms/step - loss: 0.5749 - accuracy: 0.7031\n",
            "WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n",
            "Epoch 14/30\n",
            "1/1 [==============================] - 0s 496ms/step - loss: 0.5642 - accuracy: 0.7031\n",
            "WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n",
            "Epoch 15/30\n",
            "1/1 [==============================] - 1s 519ms/step - loss: 0.5542 - accuracy: 0.7031\n",
            "WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n",
            "Epoch 16/30\n",
            "1/1 [==============================] - 1s 509ms/step - loss: 0.6406 - accuracy: 0.6250\n",
            "WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n",
            "Epoch 17/30\n",
            "1/1 [==============================] - 1s 536ms/step - loss: 0.7197 - accuracy: 0.5000\n",
            "WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n",
            "Epoch 18/30\n",
            "1/1 [==============================] - 0s 469ms/step - loss: 0.6241 - accuracy: 0.5156\n",
            "WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n",
            "Epoch 19/30\n",
            "1/1 [==============================] - 1s 519ms/step - loss: 0.6249 - accuracy: 0.6250\n",
            "WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n",
            "Epoch 20/30\n",
            "1/1 [==============================] - 0s 494ms/step - loss: 0.6006 - accuracy: 0.7344\n",
            "WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n",
            "Epoch 21/30\n",
            "1/1 [==============================] - 0s 485ms/step - loss: 0.5767 - accuracy: 0.7500\n",
            "WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n",
            "Epoch 22/30\n",
            "1/1 [==============================] - 0s 498ms/step - loss: 0.5630 - accuracy: 0.6562\n",
            "WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n",
            "Epoch 23/30\n",
            "1/1 [==============================] - 1s 505ms/step - loss: 0.5302 - accuracy: 0.7344\n",
            "WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n",
            "Epoch 24/30\n",
            "1/1 [==============================] - 0s 491ms/step - loss: 0.5095 - accuracy: 0.7344\n",
            "WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n",
            "Epoch 25/30\n",
            "1/1 [==============================] - 0s 486ms/step - loss: 0.5026 - accuracy: 0.7656\n",
            "WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n",
            "Epoch 26/30\n",
            "1/1 [==============================] - 0s 493ms/step - loss: 0.8786 - accuracy: 0.6094\n",
            "WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n",
            "Epoch 27/30\n",
            "1/1 [==============================] - 1s 526ms/step - loss: 0.7262 - accuracy: 0.4844\n",
            "WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n",
            "Epoch 28/30\n",
            "1/1 [==============================] - 0s 472ms/step - loss: 0.6329 - accuracy: 0.6406\n",
            "WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n",
            "Epoch 29/30\n",
            "1/1 [==============================] - 0s 496ms/step - loss: 0.6197 - accuracy: 0.6250\n",
            "WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n",
            "Epoch 30/30\n",
            "1/1 [==============================] - 0s 456ms/step - loss: 0.6248 - accuracy: 0.6562\n",
            "WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n",
            "Epoch 1/30\n",
            "1/1 [==============================] - 1s 794ms/step - loss: 0.7422 - accuracy: 0.4062\n",
            "WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n",
            "Epoch 2/30\n",
            "1/1 [==============================] - 0s 445ms/step - loss: 0.5616 - accuracy: 0.7656\n",
            "WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n",
            "Epoch 3/30\n",
            "1/1 [==============================] - 1s 529ms/step - loss: 0.5481 - accuracy: 0.7656\n",
            "WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n",
            "Epoch 4/30\n",
            "1/1 [==============================] - 0s 440ms/step - loss: 0.4754 - accuracy: 0.7812\n",
            "WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n",
            "Epoch 5/30\n",
            "1/1 [==============================] - 1s 514ms/step - loss: 0.4703 - accuracy: 0.7969\n",
            "WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n",
            "Epoch 6/30\n",
            "1/1 [==============================] - 0s 498ms/step - loss: 0.4516 - accuracy: 0.8125\n",
            "WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n",
            "Epoch 7/30\n",
            "1/1 [==============================] - 1s 523ms/step - loss: 0.4338 - accuracy: 0.8125\n",
            "WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n",
            "Epoch 8/30\n",
            "1/1 [==============================] - 0s 482ms/step - loss: 0.4300 - accuracy: 0.8125\n",
            "WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n",
            "Epoch 9/30\n",
            "1/1 [==============================] - 0s 481ms/step - loss: 0.4260 - accuracy: 0.8125\n",
            "WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n",
            "Epoch 10/30\n",
            "1/1 [==============================] - 0s 476ms/step - loss: 0.3892 - accuracy: 0.8125\n",
            "WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n",
            "Epoch 11/30\n",
            "1/1 [==============================] - 1s 521ms/step - loss: 0.3857 - accuracy: 0.8125\n",
            "WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n",
            "Epoch 12/30\n",
            "1/1 [==============================] - 0s 498ms/step - loss: 0.3793 - accuracy: 0.8438\n",
            "WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n",
            "Epoch 13/30\n",
            "1/1 [==============================] - 1s 516ms/step - loss: 0.4013 - accuracy: 0.8281\n",
            "WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n",
            "Epoch 14/30\n",
            "1/1 [==============================] - 0s 489ms/step - loss: 0.3614 - accuracy: 0.8438\n",
            "WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n",
            "Epoch 15/30\n",
            "1/1 [==============================] - 1s 527ms/step - loss: 0.4598 - accuracy: 0.8125\n",
            "WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n",
            "Epoch 16/30\n",
            "1/1 [==============================] - 1s 500ms/step - loss: 0.4372 - accuracy: 0.8438\n",
            "WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n",
            "Epoch 17/30\n",
            "1/1 [==============================] - 1s 513ms/step - loss: 0.4469 - accuracy: 0.8125\n",
            "WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n",
            "Epoch 18/30\n",
            "1/1 [==============================] - 0s 478ms/step - loss: 0.3979 - accuracy: 0.8438\n",
            "WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n",
            "Epoch 19/30\n",
            "1/1 [==============================] - 1s 515ms/step - loss: 0.4202 - accuracy: 0.8281\n",
            "WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n",
            "Epoch 20/30\n",
            "1/1 [==============================] - 1s 501ms/step - loss: 0.3583 - accuracy: 0.8750\n",
            "WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n",
            "Epoch 21/30\n",
            "1/1 [==============================] - 1s 512ms/step - loss: 0.3501 - accuracy: 0.8281\n",
            "WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n",
            "Epoch 22/30\n",
            "1/1 [==============================] - 0s 482ms/step - loss: 0.3694 - accuracy: 0.8594\n",
            "WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n",
            "Epoch 23/30\n",
            "1/1 [==============================] - 0s 492ms/step - loss: 0.3462 - accuracy: 0.8594\n",
            "WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n",
            "Epoch 24/30\n",
            "1/1 [==============================] - 1s 509ms/step - loss: 0.3322 - accuracy: 0.8594\n",
            "WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n",
            "Epoch 25/30\n",
            "1/1 [==============================] - 0s 489ms/step - loss: 0.3814 - accuracy: 0.8594\n",
            "WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n",
            "Epoch 26/30\n",
            "1/1 [==============================] - 0s 483ms/step - loss: 0.4339 - accuracy: 0.8125\n",
            "WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n",
            "Epoch 27/30\n",
            "1/1 [==============================] - 1s 503ms/step - loss: 0.4942 - accuracy: 0.8125\n",
            "WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n",
            "Epoch 28/30\n",
            "1/1 [==============================] - 1s 512ms/step - loss: 0.3652 - accuracy: 0.8750\n",
            "WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n",
            "Epoch 29/30\n",
            "1/1 [==============================] - 1s 516ms/step - loss: 0.3456 - accuracy: 0.8594\n",
            "WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n",
            "Epoch 30/30\n",
            "1/1 [==============================] - 0s 444ms/step - loss: 0.3404 - accuracy: 0.8750\n",
            "WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n",
            "Epoch 1/30\n",
            "1/1 [==============================] - 0s 342ms/step - loss: 1.3489 - accuracy: 0.4000\n",
            "WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n",
            "Epoch 2/30\n",
            "1/1 [==============================] - 0s 182ms/step - loss: 0.7130 - accuracy: 0.4800\n",
            "WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n",
            "Epoch 3/30\n",
            "1/1 [==============================] - 0s 177ms/step - loss: 0.6515 - accuracy: 0.6400\n",
            "WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n",
            "Epoch 4/30\n",
            "1/1 [==============================] - 0s 184ms/step - loss: 0.5964 - accuracy: 0.6800\n",
            "WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n",
            "Epoch 5/30\n",
            "1/1 [==============================] - 0s 238ms/step - loss: 0.5887 - accuracy: 0.6800\n",
            "WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n",
            "Epoch 6/30\n",
            "1/1 [==============================] - 0s 203ms/step - loss: 0.5778 - accuracy: 0.6800\n",
            "WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n",
            "Epoch 7/30\n",
            "1/1 [==============================] - 0s 204ms/step - loss: 0.5428 - accuracy: 0.6800\n",
            "WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n",
            "Epoch 8/30\n",
            "1/1 [==============================] - 0s 205ms/step - loss: 0.5063 - accuracy: 0.6800\n",
            "WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n",
            "Epoch 9/30\n",
            "1/1 [==============================] - 0s 205ms/step - loss: 0.5083 - accuracy: 0.7600\n",
            "WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n",
            "Epoch 10/30\n",
            "1/1 [==============================] - 0s 202ms/step - loss: 0.9789 - accuracy: 0.6400\n",
            "WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n",
            "Epoch 11/30\n",
            "1/1 [==============================] - 0s 207ms/step - loss: 0.5489 - accuracy: 0.7200\n",
            "WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n",
            "Epoch 12/30\n",
            "1/1 [==============================] - 0s 201ms/step - loss: 0.5557 - accuracy: 0.6800\n",
            "WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n",
            "Epoch 13/30\n",
            "1/1 [==============================] - 0s 207ms/step - loss: 0.5717 - accuracy: 0.8000\n",
            "WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n",
            "Epoch 14/30\n",
            "1/1 [==============================] - 0s 199ms/step - loss: 0.5529 - accuracy: 0.6800\n",
            "WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n",
            "Epoch 15/30\n",
            "1/1 [==============================] - 0s 203ms/step - loss: 0.5286 - accuracy: 0.8000\n",
            "WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n",
            "Epoch 16/30\n",
            "1/1 [==============================] - 0s 211ms/step - loss: 0.4835 - accuracy: 0.7200\n",
            "WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n",
            "Epoch 17/30\n",
            "1/1 [==============================] - 0s 204ms/step - loss: 0.5130 - accuracy: 0.8400\n",
            "WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n",
            "Epoch 18/30\n",
            "1/1 [==============================] - 0s 205ms/step - loss: 0.5724 - accuracy: 0.6800\n",
            "WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n",
            "Epoch 19/30\n",
            "1/1 [==============================] - 0s 207ms/step - loss: 0.5560 - accuracy: 0.6800\n",
            "WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n",
            "Epoch 20/30\n",
            "1/1 [==============================] - 0s 216ms/step - loss: 0.4939 - accuracy: 0.8000\n",
            "WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n",
            "Epoch 21/30\n",
            "1/1 [==============================] - 0s 213ms/step - loss: 0.4545 - accuracy: 0.7600\n",
            "WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n",
            "Epoch 22/30\n",
            "1/1 [==============================] - 0s 210ms/step - loss: 0.4165 - accuracy: 0.8000\n",
            "WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n",
            "Epoch 23/30\n",
            "1/1 [==============================] - 0s 204ms/step - loss: 0.4749 - accuracy: 0.8400\n",
            "WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n",
            "Epoch 24/30\n",
            "1/1 [==============================] - 0s 197ms/step - loss: 0.6097 - accuracy: 0.7200\n",
            "WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n",
            "Epoch 25/30\n",
            "1/1 [==============================] - 0s 205ms/step - loss: 0.5421 - accuracy: 0.6000\n",
            "WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n",
            "Epoch 26/30\n",
            "1/1 [==============================] - 0s 212ms/step - loss: 0.4634 - accuracy: 0.8400\n",
            "WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n",
            "Epoch 27/30\n",
            "1/1 [==============================] - 0s 202ms/step - loss: 0.4391 - accuracy: 0.7200\n",
            "WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n",
            "Epoch 28/30\n",
            "1/1 [==============================] - 0s 199ms/step - loss: 0.3860 - accuracy: 0.8800\n",
            "WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n",
            "Epoch 29/30\n",
            "1/1 [==============================] - 0s 204ms/step - loss: 0.4105 - accuracy: 0.8000\n",
            "WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n",
            "Epoch 30/30\n",
            "1/1 [==============================] - 0s 181ms/step - loss: 0.5114 - accuracy: 0.7200\n",
            "WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3IZZxeoLGgGk",
        "outputId": "2ef4d322-015d-4433-fa52-8de1c2561fff"
      },
      "source": [
        "os.chdir(\"/content/drive/MyDrive/Minor Project 3/Model 64/\")\n",
        "for i in range(3):\n",
        "  xx = np.load('xx['+str(i)+'].npy')\n",
        "  yy = np.load('yy['+str(i)+'].npy')\n",
        "\n",
        "  model.fit(xx, yy, batch_size=len(xx),epochs=20, callbacks=callbacks_list)\n",
        "  #model.fit(xx, yy, batch_size=len(xx),epochs=30)\n",
        "\n",
        "  del xx\n",
        "  del yy\n",
        "\n",
        "  modelfilename = '/content/drive/MyDrive/Minor Project 3/Checkpoints/model_64['+str(i)+'].h5' \n",
        "  model.save_weights(modelfilename)"
      ],
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/20\n",
            "1/1 [==============================] - 1s 884ms/step - loss: 0.7822 - accuracy: 0.5625\n",
            "WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n",
            "Epoch 2/20\n",
            "1/1 [==============================] - 0s 428ms/step - loss: 0.7313 - accuracy: 0.4375\n",
            "WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n",
            "Epoch 3/20\n",
            "1/1 [==============================] - 0s 434ms/step - loss: 0.6786 - accuracy: 0.6250\n",
            "WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n",
            "Epoch 4/20\n",
            "1/1 [==============================] - 0s 419ms/step - loss: 0.6650 - accuracy: 0.6406\n",
            "WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n",
            "Epoch 5/20\n",
            "1/1 [==============================] - 0s 487ms/step - loss: 0.6696 - accuracy: 0.6094\n",
            "WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n",
            "Epoch 6/20\n",
            "1/1 [==============================] - 1s 505ms/step - loss: 0.6621 - accuracy: 0.6562\n",
            "WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n",
            "Epoch 7/20\n",
            "1/1 [==============================] - 0s 482ms/step - loss: 0.6574 - accuracy: 0.6094\n",
            "WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n",
            "Epoch 8/20\n",
            "1/1 [==============================] - 0s 464ms/step - loss: 0.6293 - accuracy: 0.5781\n",
            "WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n",
            "Epoch 9/20\n",
            "1/1 [==============================] - 0s 498ms/step - loss: 0.6271 - accuracy: 0.6875\n",
            "WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n",
            "Epoch 10/20\n",
            "1/1 [==============================] - 1s 511ms/step - loss: 0.6753 - accuracy: 0.6094\n",
            "WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n",
            "Epoch 11/20\n",
            "1/1 [==============================] - 0s 474ms/step - loss: 0.6614 - accuracy: 0.5312\n",
            "WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n",
            "Epoch 12/20\n",
            "1/1 [==============================] - 0s 498ms/step - loss: 0.6197 - accuracy: 0.6250\n",
            "WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n",
            "Epoch 13/20\n",
            "1/1 [==============================] - 1s 517ms/step - loss: 0.5895 - accuracy: 0.7031\n",
            "WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n",
            "Epoch 14/20\n",
            "1/1 [==============================] - 0s 481ms/step - loss: 0.6019 - accuracy: 0.6094\n",
            "WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n",
            "Epoch 15/20\n",
            "1/1 [==============================] - 0s 485ms/step - loss: 0.7212 - accuracy: 0.4688\n",
            "WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n",
            "Epoch 16/20\n",
            "1/1 [==============================] - 0s 492ms/step - loss: 0.6197 - accuracy: 0.6094\n",
            "WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n",
            "Epoch 17/20\n",
            "1/1 [==============================] - 0s 486ms/step - loss: 0.6478 - accuracy: 0.6250\n",
            "WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n",
            "Epoch 18/20\n",
            "1/1 [==============================] - 0s 483ms/step - loss: 0.6369 - accuracy: 0.6250\n",
            "WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n",
            "Epoch 19/20\n",
            "1/1 [==============================] - 1s 510ms/step - loss: 0.5756 - accuracy: 0.7031\n",
            "WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n",
            "Epoch 20/20\n",
            "1/1 [==============================] - 0s 440ms/step - loss: 0.5924 - accuracy: 0.6250\n",
            "WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n",
            "Epoch 1/20\n",
            "1/1 [==============================] - 1s 792ms/step - loss: 0.6069 - accuracy: 0.7969\n",
            "WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n",
            "Epoch 2/20\n",
            "1/1 [==============================] - 0s 460ms/step - loss: 0.5568 - accuracy: 0.7656\n",
            "WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n",
            "Epoch 3/20\n",
            "1/1 [==============================] - 0s 430ms/step - loss: 0.5265 - accuracy: 0.7656\n",
            "WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n",
            "Epoch 4/20\n",
            "1/1 [==============================] - 0s 436ms/step - loss: 0.5233 - accuracy: 0.7812\n",
            "WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n",
            "Epoch 5/20\n",
            "1/1 [==============================] - 0s 492ms/step - loss: 0.5251 - accuracy: 0.7656\n",
            "WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n",
            "Epoch 6/20\n",
            "1/1 [==============================] - 0s 490ms/step - loss: 0.5148 - accuracy: 0.7812\n",
            "WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n",
            "Epoch 7/20\n",
            "1/1 [==============================] - 0s 487ms/step - loss: 0.5549 - accuracy: 0.7656\n",
            "WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n",
            "Epoch 8/20\n",
            "1/1 [==============================] - 1s 519ms/step - loss: 0.5161 - accuracy: 0.7812\n",
            "WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n",
            "Epoch 9/20\n",
            "1/1 [==============================] - 1s 511ms/step - loss: 0.4682 - accuracy: 0.7656\n",
            "WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n",
            "Epoch 10/20\n",
            "1/1 [==============================] - 0s 480ms/step - loss: 0.4715 - accuracy: 0.7812\n",
            "WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n",
            "Epoch 11/20\n",
            "1/1 [==============================] - 1s 520ms/step - loss: 0.4622 - accuracy: 0.7812\n",
            "WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n",
            "Epoch 12/20\n",
            "1/1 [==============================] - 0s 468ms/step - loss: 0.4583 - accuracy: 0.8125\n",
            "WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n",
            "Epoch 13/20\n",
            "1/1 [==============================] - 0s 489ms/step - loss: 0.4613 - accuracy: 0.7969\n",
            "WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n",
            "Epoch 14/20\n",
            "1/1 [==============================] - 1s 520ms/step - loss: 0.5053 - accuracy: 0.7812\n",
            "WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n",
            "Epoch 15/20\n",
            "1/1 [==============================] - 1s 524ms/step - loss: 0.5896 - accuracy: 0.7969\n",
            "WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n",
            "Epoch 16/20\n",
            "1/1 [==============================] - 0s 482ms/step - loss: 0.4342 - accuracy: 0.7969\n",
            "WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n",
            "Epoch 17/20\n",
            "1/1 [==============================] - 1s 521ms/step - loss: 0.4191 - accuracy: 0.7969\n",
            "WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n",
            "Epoch 18/20\n",
            "1/1 [==============================] - 0s 487ms/step - loss: 0.4082 - accuracy: 0.8125\n",
            "WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n",
            "Epoch 19/20\n",
            "1/1 [==============================] - 0s 463ms/step - loss: 0.3857 - accuracy: 0.7969\n",
            "WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n",
            "Epoch 20/20\n",
            "1/1 [==============================] - 0s 429ms/step - loss: 0.3705 - accuracy: 0.8438\n",
            "WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n",
            "Epoch 1/20\n",
            "1/1 [==============================] - 0s 338ms/step - loss: 1.7395 - accuracy: 0.4000\n",
            "WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n",
            "Epoch 2/20\n",
            "1/1 [==============================] - 0s 178ms/step - loss: 0.6858 - accuracy: 0.5200\n",
            "WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n",
            "Epoch 3/20\n",
            "1/1 [==============================] - 0s 177ms/step - loss: 0.5532 - accuracy: 0.6800\n",
            "WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n",
            "Epoch 4/20\n",
            "1/1 [==============================] - 0s 179ms/step - loss: 0.5433 - accuracy: 0.6800\n",
            "WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n",
            "Epoch 5/20\n",
            "1/1 [==============================] - 0s 217ms/step - loss: 0.5202 - accuracy: 0.6800\n",
            "WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n",
            "Epoch 6/20\n",
            "1/1 [==============================] - 0s 203ms/step - loss: 0.5312 - accuracy: 0.6800\n",
            "WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n",
            "Epoch 7/20\n",
            "1/1 [==============================] - 0s 201ms/step - loss: 0.4938 - accuracy: 0.6800\n",
            "WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n",
            "Epoch 8/20\n",
            "1/1 [==============================] - 0s 201ms/step - loss: 0.5688 - accuracy: 0.6400\n",
            "WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n",
            "Epoch 9/20\n",
            "1/1 [==============================] - 0s 199ms/step - loss: 0.4936 - accuracy: 0.6800\n",
            "WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n",
            "Epoch 10/20\n",
            "1/1 [==============================] - 0s 201ms/step - loss: 0.5024 - accuracy: 0.6800\n",
            "WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n",
            "Epoch 11/20\n",
            "1/1 [==============================] - 0s 200ms/step - loss: 0.4793 - accuracy: 0.8000\n",
            "WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n",
            "Epoch 12/20\n",
            "1/1 [==============================] - 0s 208ms/step - loss: 0.4687 - accuracy: 0.7200\n",
            "WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n",
            "Epoch 13/20\n",
            "1/1 [==============================] - 0s 204ms/step - loss: 0.5025 - accuracy: 0.7200\n",
            "WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n",
            "Epoch 14/20\n",
            "1/1 [==============================] - 0s 210ms/step - loss: 0.4454 - accuracy: 0.8000\n",
            "WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n",
            "Epoch 15/20\n",
            "1/1 [==============================] - 0s 202ms/step - loss: 2.1659 - accuracy: 0.6800\n",
            "WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n",
            "Epoch 16/20\n",
            "1/1 [==============================] - 0s 199ms/step - loss: 0.5972 - accuracy: 0.6400\n",
            "WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n",
            "Epoch 17/20\n",
            "1/1 [==============================] - 0s 196ms/step - loss: 0.5757 - accuracy: 0.6800\n",
            "WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n",
            "Epoch 18/20\n",
            "1/1 [==============================] - 0s 209ms/step - loss: 0.5783 - accuracy: 0.6000\n",
            "WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n",
            "Epoch 19/20\n",
            "1/1 [==============================] - 0s 198ms/step - loss: 0.5125 - accuracy: 0.7600\n",
            "WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n",
            "Epoch 20/20\n",
            "1/1 [==============================] - 0s 177ms/step - loss: 0.4765 - accuracy: 0.7200\n",
            "WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Q4gX_4Htfr3X"
      },
      "source": [
        "os.chdir(\"/content/drive/MyDrive/Minor Project 3/Model 64/\")"
      ],
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Q0_aBRf3fum1",
        "outputId": "b06183ee-090c-4f8a-e45d-673444d0ab04"
      },
      "source": [
        "for i in range(3):\n",
        "  xx = np.load('xx['+str(i)+'].npy')\n",
        "  yy = np.load('yy['+str(i)+'].npy')\n",
        "\n",
        "  #model.fit(xx, yy, batch_size=len(xx),epochs=30, callbacks=callbacks_list)\n",
        "  model.fit(xx, yy, batch_size=len(xx),epochs=30)\n",
        "\n",
        "  del xx\n",
        "  del yy\n",
        "\n",
        "  modelfilename = '/content/drive/MyDrive/Minor Project 3/Checkpoints/model_64['+str(i)+'].h5' \n",
        "  model.save_weights(modelfilename)"
      ],
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/30\n",
            "1/1 [==============================] - 19s 19s/step - loss: 0.7141 - accuracy: 0.4375\n",
            "Epoch 2/30\n",
            "1/1 [==============================] - 1s 550ms/step - loss: 0.6931 - accuracy: 0.5625\n",
            "Epoch 3/30\n",
            "1/1 [==============================] - 0s 499ms/step - loss: 0.7005 - accuracy: 0.5156\n",
            "Epoch 4/30\n",
            "1/1 [==============================] - 1s 533ms/step - loss: 0.6697 - accuracy: 0.5469\n",
            "Epoch 5/30\n",
            "1/1 [==============================] - 1s 509ms/step - loss: 0.6485 - accuracy: 0.6094\n",
            "Epoch 6/30\n",
            "1/1 [==============================] - 1s 520ms/step - loss: 0.6755 - accuracy: 0.6094\n",
            "Epoch 7/30\n",
            "1/1 [==============================] - 1s 501ms/step - loss: 0.6799 - accuracy: 0.5781\n",
            "Epoch 8/30\n",
            "1/1 [==============================] - 0s 496ms/step - loss: 0.7534 - accuracy: 0.4375\n",
            "Epoch 9/30\n",
            "1/1 [==============================] - 1s 509ms/step - loss: 0.6922 - accuracy: 0.5312\n",
            "Epoch 10/30\n",
            "1/1 [==============================] - 0s 465ms/step - loss: 0.6795 - accuracy: 0.6406\n",
            "Epoch 11/30\n",
            "1/1 [==============================] - 0s 492ms/step - loss: 0.6889 - accuracy: 0.5156\n",
            "Epoch 12/30\n",
            "1/1 [==============================] - 0s 486ms/step - loss: 0.6642 - accuracy: 0.5938\n",
            "Epoch 13/30\n",
            "1/1 [==============================] - 0s 483ms/step - loss: 0.6502 - accuracy: 0.6250\n",
            "Epoch 14/30\n",
            "1/1 [==============================] - 0s 484ms/step - loss: 0.6858 - accuracy: 0.5469\n",
            "Epoch 15/30\n",
            "1/1 [==============================] - 0s 494ms/step - loss: 0.6823 - accuracy: 0.5625\n",
            "Epoch 16/30\n",
            "1/1 [==============================] - 0s 482ms/step - loss: 0.6586 - accuracy: 0.6562\n",
            "Epoch 17/30\n",
            "1/1 [==============================] - 0s 476ms/step - loss: 0.6575 - accuracy: 0.6094\n",
            "Epoch 18/30\n",
            "1/1 [==============================] - 1s 510ms/step - loss: 0.6425 - accuracy: 0.6094\n",
            "Epoch 19/30\n",
            "1/1 [==============================] - 0s 490ms/step - loss: 0.6764 - accuracy: 0.5938\n",
            "Epoch 20/30\n",
            "1/1 [==============================] - 0s 480ms/step - loss: 0.7787 - accuracy: 0.4531\n",
            "Epoch 21/30\n",
            "1/1 [==============================] - 0s 484ms/step - loss: 0.6591 - accuracy: 0.5781\n",
            "Epoch 22/30\n",
            "1/1 [==============================] - 0s 466ms/step - loss: 0.6489 - accuracy: 0.5938\n",
            "Epoch 23/30\n",
            "1/1 [==============================] - 0s 481ms/step - loss: 0.6360 - accuracy: 0.5938\n",
            "Epoch 24/30\n",
            "1/1 [==============================] - 0s 472ms/step - loss: 0.6251 - accuracy: 0.6875\n",
            "Epoch 25/30\n",
            "1/1 [==============================] - 0s 494ms/step - loss: 0.7282 - accuracy: 0.5938\n",
            "Epoch 26/30\n",
            "1/1 [==============================] - 0s 481ms/step - loss: 0.6668 - accuracy: 0.5469\n",
            "Epoch 27/30\n",
            "1/1 [==============================] - 0s 424ms/step - loss: 0.6697 - accuracy: 0.6094\n",
            "Epoch 28/30\n",
            "1/1 [==============================] - 0s 431ms/step - loss: 0.6606 - accuracy: 0.6562\n",
            "Epoch 29/30\n",
            "1/1 [==============================] - 0s 429ms/step - loss: 0.6501 - accuracy: 0.6562\n",
            "Epoch 30/30\n",
            "1/1 [==============================] - 0s 428ms/step - loss: 0.6280 - accuracy: 0.7344\n",
            "Epoch 1/30\n",
            "1/1 [==============================] - 1s 936ms/step - loss: 0.8636 - accuracy: 0.2656\n",
            "Epoch 2/30\n",
            "1/1 [==============================] - 0s 430ms/step - loss: 0.6079 - accuracy: 0.7031\n",
            "Epoch 3/30\n",
            "1/1 [==============================] - 0s 431ms/step - loss: 0.5812 - accuracy: 0.7500\n",
            "Epoch 4/30\n",
            "1/1 [==============================] - 0s 445ms/step - loss: 0.5628 - accuracy: 0.7500\n",
            "Epoch 5/30\n",
            "1/1 [==============================] - 1s 539ms/step - loss: 0.5295 - accuracy: 0.7500\n",
            "Epoch 6/30\n",
            "1/1 [==============================] - 1s 500ms/step - loss: 0.5200 - accuracy: 0.7656\n",
            "Epoch 7/30\n",
            "1/1 [==============================] - 1s 506ms/step - loss: 0.5355 - accuracy: 0.7656\n",
            "Epoch 8/30\n",
            "1/1 [==============================] - 0s 480ms/step - loss: 0.5498 - accuracy: 0.7656\n",
            "Epoch 9/30\n",
            "1/1 [==============================] - 1s 508ms/step - loss: 0.6289 - accuracy: 0.7500\n",
            "Epoch 10/30\n",
            "1/1 [==============================] - 0s 480ms/step - loss: 0.5251 - accuracy: 0.7500\n",
            "Epoch 11/30\n",
            "1/1 [==============================] - 1s 506ms/step - loss: 0.5254 - accuracy: 0.7812\n",
            "Epoch 12/30\n",
            "1/1 [==============================] - 1s 501ms/step - loss: 0.5604 - accuracy: 0.7500\n",
            "Epoch 13/30\n",
            "1/1 [==============================] - 0s 476ms/step - loss: 0.5183 - accuracy: 0.7656\n",
            "Epoch 14/30\n",
            "1/1 [==============================] - 0s 494ms/step - loss: 0.4840 - accuracy: 0.7969\n",
            "Epoch 15/30\n",
            "1/1 [==============================] - 0s 478ms/step - loss: 0.5568 - accuracy: 0.7500\n",
            "Epoch 16/30\n",
            "1/1 [==============================] - 0s 484ms/step - loss: 0.4942 - accuracy: 0.7969\n",
            "Epoch 17/30\n",
            "1/1 [==============================] - 0s 486ms/step - loss: 0.5362 - accuracy: 0.7500\n",
            "Epoch 18/30\n",
            "1/1 [==============================] - 0s 484ms/step - loss: 0.5438 - accuracy: 0.7344\n",
            "Epoch 19/30\n",
            "1/1 [==============================] - 0s 486ms/step - loss: 0.5683 - accuracy: 0.7500\n",
            "Epoch 20/30\n",
            "1/1 [==============================] - 0s 475ms/step - loss: 0.5244 - accuracy: 0.7500\n",
            "Epoch 21/30\n",
            "1/1 [==============================] - 0s 492ms/step - loss: 0.5161 - accuracy: 0.7500\n",
            "Epoch 22/30\n",
            "1/1 [==============================] - 0s 483ms/step - loss: 0.4910 - accuracy: 0.7656\n",
            "Epoch 23/30\n",
            "1/1 [==============================] - 1s 504ms/step - loss: 0.4649 - accuracy: 0.7969\n",
            "Epoch 24/30\n",
            "1/1 [==============================] - 0s 487ms/step - loss: 0.4121 - accuracy: 0.7969\n",
            "Epoch 25/30\n",
            "1/1 [==============================] - 0s 481ms/step - loss: 0.4927 - accuracy: 0.7812\n",
            "Epoch 26/30\n",
            "1/1 [==============================] - 0s 491ms/step - loss: 0.5479 - accuracy: 0.7656\n",
            "Epoch 27/30\n",
            "1/1 [==============================] - 0s 490ms/step - loss: 0.5156 - accuracy: 0.7969\n",
            "Epoch 28/30\n",
            "1/1 [==============================] - 0s 484ms/step - loss: 0.4434 - accuracy: 0.7969\n",
            "Epoch 29/30\n",
            "1/1 [==============================] - 0s 488ms/step - loss: 0.4742 - accuracy: 0.7500\n",
            "Epoch 30/30\n",
            "1/1 [==============================] - 0s 434ms/step - loss: 0.6681 - accuracy: 0.6406\n",
            "Epoch 1/30\n",
            "1/1 [==============================] - 2s 2s/step - loss: 1.2069 - accuracy: 0.3600\n",
            "Epoch 2/30\n",
            "1/1 [==============================] - 0s 182ms/step - loss: 0.7097 - accuracy: 0.5200\n",
            "Epoch 3/30\n",
            "1/1 [==============================] - 0s 180ms/step - loss: 0.6840 - accuracy: 0.5200\n",
            "Epoch 4/30\n",
            "1/1 [==============================] - 0s 181ms/step - loss: 0.6728 - accuracy: 0.6000\n",
            "Epoch 5/30\n",
            "1/1 [==============================] - 0s 206ms/step - loss: 0.6870 - accuracy: 0.6400\n",
            "Epoch 6/30\n",
            "1/1 [==============================] - 0s 209ms/step - loss: 0.6504 - accuracy: 0.6800\n",
            "Epoch 7/30\n",
            "1/1 [==============================] - 0s 208ms/step - loss: 0.6785 - accuracy: 0.6800\n",
            "Epoch 8/30\n",
            "1/1 [==============================] - 0s 204ms/step - loss: 0.6687 - accuracy: 0.6800\n",
            "Epoch 9/30\n",
            "1/1 [==============================] - 0s 201ms/step - loss: 0.6447 - accuracy: 0.6800\n",
            "Epoch 10/30\n",
            "1/1 [==============================] - 0s 201ms/step - loss: 0.6595 - accuracy: 0.6800\n",
            "Epoch 11/30\n",
            "1/1 [==============================] - 0s 203ms/step - loss: 0.6519 - accuracy: 0.6800\n",
            "Epoch 12/30\n",
            "1/1 [==============================] - 0s 219ms/step - loss: 0.6497 - accuracy: 0.6800\n",
            "Epoch 13/30\n",
            "1/1 [==============================] - 0s 202ms/step - loss: 0.6487 - accuracy: 0.6800\n",
            "Epoch 14/30\n",
            "1/1 [==============================] - 0s 208ms/step - loss: 0.6392 - accuracy: 0.6800\n",
            "Epoch 15/30\n",
            "1/1 [==============================] - 0s 201ms/step - loss: 0.6303 - accuracy: 0.6800\n",
            "Epoch 16/30\n",
            "1/1 [==============================] - 0s 203ms/step - loss: 0.6354 - accuracy: 0.6800\n",
            "Epoch 17/30\n",
            "1/1 [==============================] - 0s 199ms/step - loss: 0.6163 - accuracy: 0.6800\n",
            "Epoch 18/30\n",
            "1/1 [==============================] - 0s 203ms/step - loss: 0.6169 - accuracy: 0.6800\n",
            "Epoch 19/30\n",
            "1/1 [==============================] - 0s 213ms/step - loss: 0.6215 - accuracy: 0.6800\n",
            "Epoch 20/30\n",
            "1/1 [==============================] - 0s 200ms/step - loss: 0.5987 - accuracy: 0.6800\n",
            "Epoch 21/30\n",
            "1/1 [==============================] - 0s 208ms/step - loss: 0.5703 - accuracy: 0.6800\n",
            "Epoch 22/30\n",
            "1/1 [==============================] - 0s 202ms/step - loss: 0.5870 - accuracy: 0.6800\n",
            "Epoch 23/30\n",
            "1/1 [==============================] - 0s 211ms/step - loss: 0.5758 - accuracy: 0.6800\n",
            "Epoch 24/30\n",
            "1/1 [==============================] - 0s 200ms/step - loss: 0.6487 - accuracy: 0.6000\n",
            "Epoch 25/30\n",
            "1/1 [==============================] - 0s 206ms/step - loss: 0.5836 - accuracy: 0.7600\n",
            "Epoch 26/30\n",
            "1/1 [==============================] - 0s 200ms/step - loss: 0.5780 - accuracy: 0.6800\n",
            "Epoch 27/30\n",
            "1/1 [==============================] - 0s 205ms/step - loss: 0.6103 - accuracy: 0.6800\n",
            "Epoch 28/30\n",
            "1/1 [==============================] - 0s 202ms/step - loss: 0.5645 - accuracy: 0.6800\n",
            "Epoch 29/30\n",
            "1/1 [==============================] - 0s 197ms/step - loss: 0.5724 - accuracy: 0.6800\n",
            "Epoch 30/30\n",
            "1/1 [==============================] - 0s 181ms/step - loss: 0.5262 - accuracy: 0.6800\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "eK9rsoSNAPqG"
      },
      "source": [
        "# Model 256"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "htDfPMjufugt"
      },
      "source": [
        "os.chdir(\"/content/drive/MyDrive/Minor Project 3/\")\n",
        "\n",
        "xx = np.load('xx.npy')\n",
        "yy = np.load('yy.npy') "
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lwhOuR35fuYi"
      },
      "source": [
        "model.fit(xx, yy, batch_size=len(xx),epochs=10, callbacks=callbacks_list)\n",
        "\n",
        "del xx\n",
        "del yy\n",
        "\n",
        "modelfilename = '/content/drive/MyDrive/Minor Project 3/Checkpoints/model_256.h5' \n",
        "model.save_weights(modelfilename)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0gNbF-tLXFNH"
      },
      "source": [
        "## Making and storing model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8sXGXDDUSEDl",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "0f13cb63-22c5-4f66-98bd-744549701125"
      },
      "source": [
        "model.fit(xx, yy, batch_size=len(xx),epochs=10, validation_data=(x_testB, y_testB_temp), callbacks=callbacks_list)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/10\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Tv_13Q1Skg_C"
      },
      "source": [
        "#Save Model Weights\n",
        "path = '/content/drive/MyDrive/Minor Project 3/Checkpoints/model_v2.h5'\n",
        "\n",
        "model.save_weights(path)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "f2Z87ndxKVhc"
      },
      "source": [
        "# Best Model Load"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "aC0Uhs3RKrm-"
      },
      "source": [
        "path = \"/content/drive/MyDrive/Minor Project 3/Checkpoints/Success 2/model_64[1].h5\""
      ],
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4MCjC-W2KZ4U"
      },
      "source": [
        "x =Input(shape=(frame, row, col))\n",
        "encoded_rows = TimeDistributed(LSTM(row_hidden))(x) \n",
        "encoded_columns =LSTM(col_hidden)(encoded_rows)\n",
        "\n",
        "layer2 = Dense(128, activation='relu')(encoded_columns)\n",
        "layer3 = Dropout(.2)(layer2)\n",
        "layer4 = Dense(64, activation='relu')(layer3)\n",
        "layer5 = Dropout(.2)(layer4)\n",
        "prediction = Dense(num_classes, activation='softmax')(layer5)\n",
        "\n",
        "model = Model(x, prediction)\n",
        "model.load_weights(path)"
      ],
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6RvbFUAZLozt",
        "outputId": "c6a0dd1d-5011-4b26-95b2-8ef0d523dfb5"
      },
      "source": [
        "model.compile(loss='categorical_crossentropy', optimizer='NAdam', metrics=['accuracy']) \n",
        "model.summary()"
      ],
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"model\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "input_2 (InputLayer)         [(None, 99, 144, 256)]    0         \n",
            "_________________________________________________________________\n",
            "time_distributed_1 (TimeDist (None, 99, 128)           197120    \n",
            "_________________________________________________________________\n",
            "lstm_3 (LSTM)                (None, 128)               131584    \n",
            "_________________________________________________________________\n",
            "dense (Dense)                (None, 128)               16512     \n",
            "_________________________________________________________________\n",
            "dropout (Dropout)            (None, 128)               0         \n",
            "_________________________________________________________________\n",
            "dense_1 (Dense)              (None, 64)                8256      \n",
            "_________________________________________________________________\n",
            "dropout_1 (Dropout)          (None, 64)                0         \n",
            "_________________________________________________________________\n",
            "dense_2 (Dense)              (None, 2)                 130       \n",
            "=================================================================\n",
            "Total params: 353,602\n",
            "Trainable params: 353,602\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mv8LL-G3V7tX"
      },
      "source": [
        "# loss = model.history['loss']\n",
        "# val_loss = model.history['val_loss']\n",
        "# epochs = range(epochs)\n",
        "# plt.figure()\n",
        "# plt.plot(epochs, loss, 'bo', label='Training loss')\n",
        "# plt.plot(epochs, val_loss, 'b', label='Validation loss')\n",
        "# plt.title('Training and validation loss')\n",
        "# plt.legend()\n",
        "# plt.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0VYaJvkAMuos"
      },
      "source": [
        "os.chdir(\"/content/drive/MyDrive/Minor Project 3/Model 64/\")\n",
        "x_test_zero = np.load('x_test_batch[0].npy')\n",
        "x_test_one = np.load('x_test_batch[1].npy')"
      ],
      "execution_count": 54,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hn_pA21FOom3"
      },
      "source": [
        "x_test = np.concatenate((x_test_zero, x_test_one), axis = 0)\n",
        "y_test = np.load('y_test_np.npy')"
      ],
      "execution_count": 55,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_PsQpzXFNq3o",
        "outputId": "39786099-054e-494b-c21d-e32f6bdb666b"
      },
      "source": [
        "print('x_test_zero size = ', x_test_zero.shape)\n",
        "print('x_test_one size = ', x_test_one.shape)\n",
        "print('x_test size = ', x_test.shape)\n",
        "print('y_test size = ', y_test.shape)"
      ],
      "execution_count": 56,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "x_test_zero size =  (64, 99, 144, 256)\n",
            "x_test_one size =  (64, 99, 144, 256)\n",
            "x_test size =  (128, 99, 144, 256)\n",
            "y_test size =  (128, 2)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QHGFy1NjV7Wn",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "3792887d-356f-4164-b782-967373b5f7fd"
      },
      "source": [
        "scores = model.evaluate(x_test, y_test, verbose=0) \n",
        "print('Test loss:', scores[0]) \n",
        "print('Test accuracy:', scores[1])"
      ],
      "execution_count": 57,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Test loss: 0.9970162510871887\n",
            "Test accuracy: 0.59375\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bKP1fbJfJvhH"
      },
      "source": [
        "# Alert System"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wmCVK72AZ6-5"
      },
      "source": [
        "def print_accuracy(flag, camera_number):\n",
        "  if path[-6] == 'i':\n",
        "    print('Prediction Probabilities are\\nNegative = ', flag[0][1],'\\nPositive = ',flag[0][0])\n",
        "    print('Accident Detected\\n')\n",
        "    send_alert(camera_number)\n",
        "\n",
        "  else:\n",
        "    print('Prediction Probabilities are\\nNegative = ', flag[0][0],'\\nPositive = ',flag[0][1])\n",
        "    print('No accident')"
      ],
      "execution_count": 123,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "a0AictBv8i3E"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Ur5lqwmzfizI",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "acf53479-c5df-4483-9c60-a4d9f674d87e"
      },
      "source": [
        "#path = \"/content/drive/MyDrive/Minor Project 3/Run Cases/Positive/\"\n",
        "path = \"/content/drive/MyDrive/Minor Project 3/Run Cases/Negative/\"\n",
        "video_name = '104.mp4'\n",
        "\n",
        "camera_number = 1\n",
        "\n",
        "cap = cv2.VideoCapture(path+video_name)\n",
        "property_id = int(cv2.CAP_PROP_FRAME_COUNT) \n",
        "length = int(cv2.VideoCapture.get(cap, property_id))\n",
        "count = 0\n",
        "success = 1\n",
        "\n",
        "#print(length)\n",
        "\n",
        "if length > 100:\n",
        "  cut = length-99\n",
        "else:\n",
        "  cut = 0\n",
        "\n",
        "#os.chdir(\"/content/drive/MyDrive/Minor Project 3/Run Cases/Frames/\")\n",
        "#dir =  path+'/'+video_name\n",
        "#os.mkdir(video_name)\n",
        "#os.chdir(\"/content/drive/MyDrive/Minor Project 3/Run Cases/Frames/\"+video_name)\n",
        "\n",
        "video_ready = []\n",
        "\n",
        "for i in range(length):\n",
        "  success, image = cap.read()\n",
        "  #print(success)\n",
        "  if count >= cut :\n",
        "    n = count-cut\n",
        "    #cv2.imwrite(str(n)+'.jpg', image)\n",
        "    tmp = skimage.color.rgb2gray(np.array(image))\n",
        "    tmp = transform.resize(tmp, (144, 256))\n",
        "    video_ready.append(tmp)\n",
        "  count += 1\n",
        "\n",
        "#path = \"/content/drive/MyDrive/Minor Project 3/Run Cases/Frames/\"\n",
        "#cur_video = glob.glob(path + '*.mp4') \n",
        "\n",
        "#video_ready = make_dataset(cur_video)\n",
        "\n",
        "video_ready = [video_ready]\n",
        "video_ready = np.array(video_ready)\n",
        "\n",
        "video_ready.shape\n",
        "\n",
        "flag = model.predict(video_ready)\n",
        "\n",
        "print_accuracy(flag, camera_number)"
      ],
      "execution_count": 127,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Prediction Probabilities are\n",
            "Negative =  0.52326816 \n",
            "Positive =  0.47673184\n",
            "No accident\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1vSHIehsEv01"
      },
      "source": [
        "import pandas as pd\n",
        "import smtplib\n",
        "import os\n",
        "\n",
        "'''\n",
        "Change these to your credentials and name\n",
        "\n",
        "'''\n",
        "\n",
        "def send_alert(camera_number):\n",
        "  your_email = 'minorproject888@gmail.com'\n",
        "  your_password = 'dssvouztedbhbrjt'\n",
        "\n",
        "  # If you are using something other than gmail\n",
        "  # then change the 'smtp.gmail.com' and 465 in the line below\n",
        "  server = smtplib.SMTP_SSL('smtp.gmail.com', 465)\n",
        "  server.ehlo()\n",
        "  server.login(your_email, your_password)\n",
        "\n",
        "  # Read the file\n",
        "  email_list = pd.read_excel(\"/content/drive/MyDrive/Minor Project 3/Email/EmailL.xlsx\")\n",
        "  camera = pd.read_excel(\"/content/drive/MyDrive/Minor Project 3/Email/Cameras.xlsx\")\n",
        "\n",
        "  gps_location = camera.loc[camera_number]\n",
        "\n",
        "  # Get all the Names, Email Addreses, Subjects and Messages\n",
        "  all_emails = email_list['Email']\n",
        "\n",
        "  # Loop through the emails\n",
        "  for idx in range(len(all_emails)):\n",
        "\n",
        "      # Get each records name, email, subject and message\n",
        "      email = all_emails[idx]\n",
        "      subject = 'Requesting Immediate Help'\n",
        "      message = 'Urgent - An accident has occurred.\\nLocation -> ' + str(gps_location['Location']) + '\\nGoogle Maps Link -> ' + str(gps_location['GPS Link'])\n",
        "      # Create the email to send\n",
        "      full_email = (\"From: <{0}>\\n\"\n",
        "                    \"To:  <{1}>\\n\"\n",
        "                    \"Subject: {2}\\n\\n\"\n",
        "                    \"{3}\"\n",
        "                    .format(your_email, email, subject, message))\n",
        "\n",
        "      # In the email field, you can add multiple other emails if you want\n",
        "      # all of them to receive the same text\n",
        "      try:\n",
        "          server.sendmail(your_email, [email], full_email)\n",
        "          print('Email to {} successfully sent!\\n'.format(email))\n",
        "      except Exception as e:\n",
        "          print('Email to {} could not be sent :( because {}\\n\\n'.format(email, str(e)))\n",
        "\n",
        "  # Close the smtp server\n",
        "  server.close()"
      ],
      "execution_count": 122,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "NLA9TGejxKUM",
        "outputId": "d79d536b-a91b-432a-b6a8-c66a9ecfc474"
      },
      "source": [
        "camera_number = 1\n",
        "camera = pd.read_excel(\"/content/drive/MyDrive/Minor Project 3/Email/Cameras.xlsx\")\n",
        "\n",
        "gps_location = camera.loc[camera_number]\n",
        "gps_location"
      ],
      "execution_count": 111,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Camera Number                                         2\n",
              "Location         Gopal Nagar, Model Town, Delhi, 110009\n",
              "GPS Link          https://goo.gl/maps/NFPbfA7jwQxLZ5Ro6\n",
              "Name: 1, dtype: object"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 111
        }
      ]
    }
  ]
}